<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>합성곱 신경망과 튜닝 기법(CNN)</title>
    <link rel="stylesheet" href="style-Deeplearning5.css">
</head>
<body>
    <div class="content-container">
        <!-- 제목 -->
        <h1 class="left"> 합성곱 신경망과 튜닝 기법 </h1>

        <!-- 합성곱 신경망 실습 -->
        <div class="description-section">
            <h2> 라이브러리와 GPU 할당 </h2>
            <div class="image-section.left">
              <img src="Deep learning5 images/1.png" alt="라이브러리와 GPU 할당" class="deep-learning-image">
            </div>
        </div>

      <!-- CIFAR10 데이터로 합성곱 신경망 적용 -->
        <div class="description-section">
            <h2> CIFAR10 데이터로 합성곱 신경망 적용 </h2>
            <div class="image-section.left">
              <img src="Deep learning5 images/2.png" alt="CIFAR10 데이터로 합성곱 신경망 적용" class="deep-learning-image">
            </div>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/3.png" alt="Deeplearning 세 번째 이미지" class="opencv-image">
        </div>
      <div class="description-section">
            <ol>
                <li><code>len(train_set)</code><br>
                    훈련 데이터셋에 50,000개의 이미지가 포함되어 있다는 것을 의미합니다.
                </li>
                <li><code>len(test_set)</code><br>
                    테스트 데이터셋에는 10,000개의 이미지가 포함되어 있다는 것을 보여줍니다.
                </li>
                <li><code>classes = train_set.classes</code><br>
                    데이터셋에 포함된 10개의 클래스는 다음과 같습니다(airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)
                </li>
                <li><code>len(classes)</code><br>
                    총 10개의 클래스가 존재한다는 것을 확인할 수 있습니다.
                </li>
            </ol>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/4.png" alt="Deeplearning 네 번째 이미지" class="opencv-image">
        </div>
      <div class="description-section">
            <ol>
                <li><code>batch_size = 128</code><br>
                  배치 크기를 설정하여 CNN 학습 시 한 번에 처리할 데이터 양을 지정합니다.<br>
                  이는 모델 학습과 추론의 효율성을 높이고 메모리 사용을 최적화합니다.
                </li>
                <li><code>DataLoader</code><br>
                  CNN 학습에 필요한 데이터 로딩 및 배치 구성을 담당합니다.<br>
                  <code>shuffle=True</code>는 데이터 순서를 무작위로 섞어 모델이 데이터를 고르게 학습하도록 합니다(훈련 데이터에 중요).
                </li>
                <li><code>images.shape</code><br>
                  <code>(128, 3, 32, 32)</code> → CNN 모델에 입력되는 데이터 형식.<br>
                  -128개의 이미지(batch size).<br>
                  -각 이미지가 3채널(RGB)이고 크기는 32x32.<br>
                  CNN은 이 형식의 데이터를 입력으로 받아 특징을 추출합니다.
                </li>
            </ol>
      </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/5.png" alt="Deeplearning 다섯 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><code>plt.figure(figsize=(10, 3))</code><br>
                  출력 이미지 전체의 크기를 설정합니다. 너비는 10, 높이는 3입니다.
                </li>
                <li><code>for i in range(20)</code><br>
                  처음 20개의 이미지를 반복하며 출력합니다.
                </li>
                <li><codeax = plt.subplot(2, 10, i + 1)</code><br>
                  서브플롯(subplot)을 생성합니다.<br>
                    2행 10열의 그리드에서 현재 위치(i + 1)에 이미지를 그립니다.
                </li>
                <li><code>image, label = train_set[i]</code><br>
                    CIFAR-10 데이터셋에서 이미지<code>(image)</code>와 해당 레이블<code>(label)</code>을 가져옵니다.
                </li>
                <li><code>plt.imshow(np.transpose(image, (1, 2, 0)))</code><br>
                    이미지를 출력합니다.<br>
                    PyTorch 데이터는 <code>(채널, 높이, 너비)</code> 형식이므로 <code>np.transpose</code>를 사용해 <code>(높이, 너비, 채널)</code>로 변환해야 <code>matplotlib</code>에서 제대로 표시됩니다.
                </li>
                <li><code>ax.set_title(f'{classes[label]}')</code><br>
                이미지의 레이블(클래스 이름)을 제목으로 표시합니다.
                </li>
                <li><code>ax.get_xaxis().set_visible(False)와 ax.get_yaxis().set_visible(False)</code><br>
                x축과 y축을 숨겨 시각적으로 깔끔하게 만듭니다.
                </li>
                <li><code>plt.show()</code><br>
                작성된 모든 플롯을 출력합니다.
                </li>
            </ol>
      </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/6.png" alt="Deeplearning 여섯 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><code>CNN1 클래스 정의</code><br>
                    CNN1 클래스는 PyTorch의 <code>nn.Module</code>을 상속받아 간단한 CNN 모델을 정의합니다.
                </li>
                <li><code>__init__ 메서드</code><br>
                    네트워크의 층을 정의합니다.
                    <ul>
                        <li><code>self.layer1</code>:<br>
                            합성곱 (<code>nn.Conv2d</code>) → ReLU → MaxPooling으로 구성된 합성곱 블록.
                            <ul>
                                <li>입력 채널: 3 (RGB 이미지), 출력 채널: 32.</li>
                            </ul>
                        </li>
                        <li><code>self.l1</code>:<br>
                            완전 연결층 (<code>nn.Linear</code>)으로, 입력 크기: <code>32 * 16 * 16</code>, 출력 크기: 50.
                        </li>
                        <li><code>self.l2</code>:<br>
                            완전 연결층 (<code>nn.Linear</code>)으로, 입력 크기: 50, 출력 크기: 10 (클래스 수).
                        </li>
                    </ul>
                </li>
                <li><code>forward 메서드</code><br>
                    데이터의 순차적인 흐름을 정의합니다:
                    <ul>
                        <li><code>self.layer1(x)</code>: 합성곱과 맥스풀링 처리.</li>
                        <li><code>x.view(x.size(0), -1)</code>: 출력을 평탄화 (<code>flatten</code>).</li>
                        <li><code>self.l1(x) → self.relu(x) → self.l2(x)</code>: 완전 연결층과 활성화 함수 적용.</li>
                    </ul>
                    최종 출력: 클래스별 점수.
                </li>
            </ol>
        </div>

         <div class="image-section.left">
            <img src="Deep learning5 images/7.png" alt="Deeplearning 일곱 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><code>torch.cuda.manual_seed(123)</code><br>
                    CUDA 연산에서 난수 생성기의 시드를 고정하여 결과를 재현 가능하게 만듭니다.
                </li>
                <li><code>model = CNN1()</code><br>
                    이전에 정의한 CNN1 모델을 인스턴스화합니다.
                </li>
                <li><code>model.to(device)</code><br>
                    모델을 <code>device</code>로 이동시킵니다. (예: GPU 또는 CPU)
                </li>
                <li><code>lr = 1e-3</code><br>
                    학습률(<code>learning rate</code>)을 0.001로 설정합니다.
                </li>
                <li><code>criterion = nn.CrossEntropyLoss()</code><br>
                    손실 함수로 교차 엔트로피 손실을 사용합니다.
                    <ul>
                        <li>분류 문제에서 주로 사용되며, 모델 출력(클래스 확률)과 실제 레이블 간 차이를 계산합니다.</li>
                    </ul>
                </li>
                <li><code>optimizer = torch.optim.Adam(model.parameters(), lr=lr)</code><br>
                    옵티마이저로 Adam을 사용합니다.
                    <ul>
                        <li>모델의 가중치를 학습하기 위해 설정된 학습률(<code>lr=1e-3</code>)로 매개변수를 업데이트합니다.</li>
                    </ul>
                </li>
                <li><code>history = np.zeros((0, 5))</code><br>
                    학습 기록을 저장할 빈 배열을 생성합니다.
                    <ul>
                        <li>5개의 열은 학습/검증 손실 및 정확도를 저장하는 용도로 보입니다.</li>
                    </ul>
                </li>
            </ol>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/8.png" alt="Deeplearning 여덟 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 단계</strong>
                    <ul>
                        <li><code>for images, labels in tqdm(train_loader):</code><br>
                            <strong>train_loader</strong>에서 배치 데이터를 가져옵니다.<br>
                            <strong>tqdm:</strong> 학습 진행 상황을 시각적으로 표시.
                        </li>
                        <li><code>inputs, labels = images.to(device), labels.to(device)</code><br>
                            데이터를 GPU/CPU로 전송합니다.
                        </li>
                        <li><code>optimizer.zero_grad()</code><br>
                            그래디언트를 초기화합니다.
                        </li>
                        <li><code>outputs = model(inputs)</code><br>
                            순전파(<strong>forward pass</strong>)를 통해 예측값 계산.
                        </li>
                        <li><code>loss_model = criterion(outputs, labels)</code><br>
                            손실 함수(<strong>criterion</strong>)를 사용해 손실 계산.
                        </li>
                        <li><code>loss_model.backward()</code><br>
                            역전파(<strong>backward pass</strong>)로 그래디언트 계산.
                        </li>
                        <li><code>optimizer.step()</code><br>
                            옵티마이저로 가중치 업데이트.
                        </li>
                        <li><code>train_loss += loss_model.item()</code><br>
                            현재 배치의 손실 값 누적.
                        </li>
                        <li><code>train_acc += (pred == labels).sum().item()</code><br>
                            예측값과 실제값 비교 후 정확도 계산.
                        </li>
                    </ul>
                </li>
                <li><strong>테스트 단계</strong>
                    <ul>
                        <li><code>for images_test, labels_test in test_loader:</code><br>
                            테스트 데이터 배치를 가져옵니다.
                        </li>
                        <li><code>outputs_test = model(inputs_test)</code><br>
                            테스트 데이터에서 모델 예측값 계산.
                        </li>
                        <li><code>loss_test_model = criterion(outputs_test, labels_test)</code><br>
                            테스트 손실 계산.
                        </li>
                        <li><code>pred_test = outputs_test.max(axis=1)[1]</code><br>
                            각 클래스 확률 중 가장 높은 클래스 예측값 반환.
                        </li>
                        <li><code>test_loss += loss_test_model.item()</code><br>
                            테스트 데이터 손실 값 누적.
                        </li>
                        <li><code>test_acc += (pred_test == labels_test).sum().item()</code><br>
                            테스트 정확도 계산.
                        </li>
                    </ul>
                </li>
                <li><strong>에포크별 결과 계산</strong>
                    <ul>
                        <li><code>train_loss /= n_train</code> & <code>test_loss /= n_test</code><br>
                            학습/테스트 손실 평균 계산.
                        </li>
                        <li><code>train_acc /= n_train</code> & <code>test_acc /= n_test</code><br>
                            학습/테스트 정확도 비율 계산.
                        </li>
                    </ul>
                </li>
                <li><strong>결과 출력 및 기록</strong>
                    <ul>
                        <li><code>print(f'Epoch {epoch+1}/{num_epochs}, ...')</code><br>
                            각 에포크별 학습/테스트 손실 및 정확도 출력.
                        </li>
                        <li><code>item = np.array([...])</code><br>
                            결과를 배열로 저장.
                        </li>
                        <li><code>history = np.vstack([history, item])</code><br>
                            기록(<strong>history</strong>)에 저장.
                        </li>
                    </ul>
                </li>
            </ol>
        </div>
        <div class="description-section">
            <h4>핵심 포인트</h4>
            <ul>
                <li><strong>훈련 단계:</strong>
                    <ul>
                        <li>데이터 로드 → 순전파 → 손실 계산 → 역전파 → 가중치 업데이트.</li>
                    </ul>
                </li>
                <li><strong>테스트 단계:</strong>
                    <ul>
                        <li>데이터 로드 → 예측 → 손실 및 정확도 평가.</li>
                    </ul>
                </li>
                <li><strong>결과 출력:</strong>
                    <ul>
                        <li>에포크별 손실과 정확도를 기록해 모델 학습 상태를 모니터링.</li>
                    </ul>
                </li>
            </ul>
            <p><strong>결론:</strong> 학습과 테스트 단계를 반복하며, 모델 성능(손실 및 정확도)을 추적하고 출력합니다.</p>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/9.png" alt="Deeplearning 아홉 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol><li><code>history</code>:
                <ul>
                    <li>학습 과정에서 저장된 손실과 정확도 데이터를 담고 있는 배열.</li>
                    <li>형식: [<code>에포크, train_loss, train_acc, test_loss, test_acc</code>]</li>
                </ul>
            </li>
                <li>초기 상태 출력:
                    <ul>
                        <li><code>print(f'초기 손실: 손실 = {history[0, 3]:.5f} ...')</code>: 첫 번째 에포크의 테스트 손실과 정확도 출력.</li>
                        <li><code>history[0, 3]</code>: 첫 번째 에포크의 테스트 손실.</li>
                        <li><code>history[0, 4]</code>: 첫 번째 에포크의 테스트 정확도.</li>
                    </ul>
                </li>
                <li>최종 상태 출력:
                    <ul>
                        <li><code>print(f'최종 손실: 손실 = {history[-1, 3]:.5f} ...')</code>: 마지막 에포크의 테스트 손실과 정확도 출력.</li>
                        <li><code>history[-1, 3]</code>: 마지막 에포크의 테스트 손실.</li>
                        <li><code>history[-1, 4]</code>: 마지막 에포크의 테스트 정확도.</li>
                    </ul>
                </li>
            </ol>

            <h2>결과</h2>
            <ul>
                <li><strong>초기 상태:</strong>
                    <ul>
                        <li><strong>손실:</strong> 0.01137</li>
                        <li><strong>정확도:</strong> 0.49540 (약 49.54%)</li>
                        <li>모델이 학습 초기에는 낮은 정확도를 보임.</li>
                    </ul>
                </li>
                <li><strong>최종 상태:</strong>
                    <ul>
                        <li><strong>손실:</strong> 0.00832</li>
                        <li><strong>정확도:</strong> 0.64610 (약 64.61%)</li>
                        <li>학습 후 모델의 정확도가 크게 향상됨.</li>
                    </ul>
                </li>
            </ul>
        </div>


        <div class="image-section.left">
            <img src="Deep learning5 images/10.png" alt="Deeplearning 열 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 손실 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 1], 'b', label='Train error')</code></li>
                        <li><code>history[:, 0]</code>: 에포크 값 (x축).</li>
                        <li><code>history[:, 1]</code>: 훈련 데이터 손실 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train error'</code>: 범례에 "Train error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 손실 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 3], 'k', label='Test error')</code></li>
                        <li><code>history[:, 3]</code>: 테스트 데이터 손실 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test error'</code>: 범례에 "Test error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Loss')</code>: y축 이름 설정 (손실 값).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>
            
            <h4>그래프 해석</h4>
            <ul>
                <li><strong>훈련 손실:</strong> 에포크가 증가함에 따라 손실 값이 꾸준히 감소.<br>
                    이는 모델이 훈련 데이터에 대해 점점 더 잘 학습하고 있음을 나타냄.</li>
                <li><strong>테스트 손실:</strong> 초기에 감소하다가 에포크가 진행됨에 따라 약간의 변동이 있음.<br>
                    모델이 테스트 데이터에도 적절히 학습했음을 보여줌.</li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/11.png" alt="Deeplearning 열 한 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 정확도 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 2], 'b', label='Train Accuracy')</code></li>
                        <li><code>history[:, 0]</code>: 에포크 값 (x축).</li>
                        <li><code>history[:, 2]</code>: 훈련 데이터 정확도 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train Accuracy'</code>: 범례에 "Train Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 4], 'k', label='Test Accuracy')</code></li>
                        <li><code>history[:, 4]</code>: 테스트 데이터 정확도 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test Accuracy'</code>: 범례에 "Test Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Accuracy')</code>: y축 이름 설정 (정확도).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>
            
            <h4>그래프 해석</h4>
            <ul>
                <li><strong>훈련 정확도:</strong>
                    <ul>
                        <li>초기 정확도에서 빠르게 상승.</li>
                        <li>에포크가 증가함에 따라 정확도가 약 75%에 도달.</li>
                        <li>이는 모델이 훈련 데이터에 대해 점진적으로 학습했음을 보여줌.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도:</strong>
                    <ul>
                        <li>처음에 약간의 변동이 있었으나, 안정적으로 증가.</li>
                        <li>최종적으로 테스트 정확도가 약 65%에 도달.</li>
                        <li>훈련 정확도와 테스트 정확도 간 간격이 좁아져, 과적합의 위험이 낮음을 나타냄.</li>
                    </ul>
                </li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/12.png" alt="Deeplearning 열 두 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ul>
        <li><code>class CNN(nn.Module):</code><br>
            <strong>CNN:</strong> PyTorch의 <code>nn.Module</code>을 상속받아 정의된 단일 합성곱 신경망 클래스.</li>
                <li><code>def __init__(self):</code><br>
                    <strong>__init__:</strong> 클래스에서 모델의 구조를 초기화.</li>
            </ul>
            
            <ul>
        <li><code>self.layers = nn.Sequential(...)</code>
            <ul>
                <li><code>nn.Conv2d:</code> 입력 채널을 수용하고, 채널 수를 점차 증가시키며 특징 추출.</li>
                <li><code>nn.ReLU:</code> 비선형성을 추가해 학습 가능성을 증가.</li>
                <li><code>nn.MaxPool2d:</code> 공간 크기를 줄여 모델의 효율성을 증가.</li>
            </ul>
        </li>
                <li>채널 증가: 3 → 32 → 64 → 128.</li>
            </ul>
            
            <ul>
        <li><code>self.l1 = nn.Linear(128*4*4, 128)</code>: 특성을 1차원 벡터로 변환.</li>
                <li><code>self.l2 = nn.Linear(128, 10)</code>: 클래스 점수 계산.</li>
            </ul>
            
            <ul>
                <li><code>def forward(self, x):</code>
                    <ul>
                        <li><code>self.layer1(x):</code> 합성곱, ReLU, 풀링을 통해 특징 추출.</li>
                        <li><code>x.view(x.size(0), -1):</code> 특징을 1차원 벡터로 변환.</li>
                        <li><code>self.l1(x) → self.l2(x):</code> 완전 연결층을 통해 클래스 점수 계산.</li>
                    </ul>
                </li>
            </ul>
            
            <ul>
                <li>입력: 3채널 RGB 이미지 (예: CIFAR-10, 크기 32x32).</li>
                <li>합성곱 블록:
                    <ul>
                        <li>채널 증가: 3 → 32 → 64 → 128.</li>
                        <li>각 블록마다 ReLU와 MaxPooling으로 특징 추출.</li>
                    </ul>
                </li>
                <li>완전 연결층:
                    <ul>
                        <li>추출된 특징을 활성화해 10개의 클래스에 대한 점수 계산.</li>
                    </ul>
                </li>
                <li>출력: 각 클래스에 대한 점수.</li>
            </ul>
        </div>

         <div class="image-section.left">
            <img src="Deep learning5 images/13.png" alt="Deeplearning 열 세 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ul>
                <li><strong>Dropout의 역할:</strong>
                    <ul>
                        <li>과적합 방지를 위해 활성화된 뉴런을 랜덤하게 비활성화.</li>
                        <li>학습 중 특정 뉴런에 과도하게 의존하지 않도록 도움.</li>
                    </ul>
                </li>
                <li><strong>Dropout 층 추가:</strong>
                    <ul>
                        <li><code>nn.Dropout(p)</code> 사용.</li>
                        <li><code>p</code>: 비활성화할 뉴런의 비율 (예: <code>p=0.2</code>는 20%).</li>
                    </ul>
                </li>
            </ul>
            
            <ul>
                <li><code>self.layer1 = nn.Sequential(...)</code>: 각 <code>MaxPool2d</code> 층 뒤에 Dropout 추가.
                    <ul>
                        <li>비율은 점진적으로 증가 (<code>p=0.2 → 0.3 → 0.4</code>).</li>
                        <li>고차원의 특징 학습에 과적합 방지를 강화.</li>
                    </ul>
                </li>
            </ul>
            
            <ul>
                <li><code>self.l1 = nn.Linear(128*4*4, 128)</code>: 완전 연결층.</li>
                <li><code>self.l2 = nn.Linear(128, 10)</code>: 클래스 점수 계산.</li>
                <li><code>self.dropout1 = nn.Dropout(0.4)</code>: 완전 연결층에서도 Dropout 추가.</li>
            </ul>
            
            <ul>
                <li><code>self.layer1(x)</code>: 합성곱 및 Dropout 적용.</li>
                <li><code>x.view(x.size(0), -1)</code>: 특징 벡터를 1차원으로 변환.</li>
                <li><code>self.dropout1(x)</code>: 완전 연결층에서도 Dropout 적용.</li>
            </ul>
            
            <ul>
                <li><strong>입력:</strong> RGB 이미지 (<code>3채널</code>, 크기 <code>32x32</code>).</li>
                <li><strong>Dropout 층:</strong>
                    <ul>
                        <li>합성곱 층: 각 <code>MaxPool2d</code> 뒤에 추가 (<code>p=0.2 → 0.3 → 0.4</code>).</li>
                        <li>완전 연결층: <code>p=0.4</code>로 과적합 방지.</li>
                    </ul>
                </li>
                <li><strong>출력:</strong> 10개의 클래스 점수.</li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/14.png" alt="Deeplearning 열 네 번째 이미지" class="opencv-image">
        </div>        
        <div class="description-section">
            <ul>
                <li><strong>Batch Normalization (<code>nn.BatchNorm2d</code>):</strong>
                    <ul>
                        <li>합성곱 층의 출력값을 정규화하여 학습 안정화 및 속도 향상.</li>
                        <li>각 채널의 평균과 분산을 정규화한 후 학습 가능한 파라미터로 다시 스케일링과 시프트.</li>
                    </ul>
                </li>
            </ul>
            <ul>
                <li><code>self.bn1 = nn.BatchNorm2d(32)</code>: 첫 번째 합성곱 층의 출력 채널에 맞게 Batch Normalization 초기화.</li>
                <li>각 합성곱 층의 출력 채널에 맞춰 Batch Normalization 정의 (<code>bn1</code> ~ <code>bn6</code>).</li>
            </ul>            
            <ul>
                <li><code>self.layer1 = nn.Sequential(...)</code>
                    <ul>
                        <li>각 <code>nn.Conv2d</code> 뒤에 <code>BatchNorm</code> 추가.</li>
                        <li><strong>위치:</strong> ReLU 활성화 함수 이전에 사용하여 출력값을 정규화.</li>
                    </ul>
                </li>
            </ul>            
            <ul>
                <li>완전 연결층에서는 Batch Normalization을 사용하지 않음.</li>
            </ul>
            <ul>
                <li><code>self.layer1(x)</code>: Batch Normalization, ReLU, MaxPool, Dropout 순으로 진행.</li>
                <li><code>x.view(x.size(0), -1)</code>: 특징 벡터를 1차원으로 변환.</li>
                <li><code>self.dropout1(x)</code>: Dropout 적용.</li>
            </ul>            
            <ul>
                <li><strong>Batch Normalization 추가:</strong>
                    <ul>
                        <li>모든 합성곱 층의 출력값을 정규화하여 학습 속도를 높이고 안정성 향상.</li>
                        <li>과적합 방지 및 일반화 성능 향상.</li>
                    </ul>
                </li>
                <li><strong>Dropout:</strong>
                    <ul>
                        <li>합성곱 층과 완전 연결층에서 Dropout으로 뉴런 비활성화.</li>
                    </ul>
                </li>
                <li><strong>출력:</strong> 10개 클래스의 점수.</li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/15.png" alt="Deeplearning 열 다섯 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 손실 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 1], 'b', label='Train error')</code></li>
                        <li><code>history[:, 0]</code>: 에포크 값 (x축).</li>
                        <li><code>history[:, 1]</code>: 훈련 데이터 손실 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train error'</code>: 범례에 "Train error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 손실 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 3], 'k', label='Test error')</code></li>
                        <li><code>history[:, 3]</code>: 테스트 데이터 손실 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test error'</code>: 범례에 "Test error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Loss')</code>: y축 이름 설정 (손실 값).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>
                <h4> 그래프 해석</h4>
            <ul>
                <li><strong>훈련 손실 (Train error):</strong>
                    <ul>
                        <li><strong>초기 상태:</strong> 에포크 초반 손실이 높음.</li>
                        <li><strong>진행 상황:</strong> 에포크가 진행될수록 손실이 꾸준히 감소.</li>
                        <li><strong>최종 상태:</strong> 낮은 손실 값을 기록하며, 모델이 훈련 데이터에 잘 적응했음을 의미.</li>
                    </ul>
                </li>
                <li><strong>테스트 손실 (Test error):</strong>
                    <ul>
                        <li><strong>초기 상태:</strong> 테스트 손실도 높은 상태로 시작.</li>
                        <li><strong>진행 상황:</strong> 에포크 초반 빠르게 감소, 이후 약간의 변동 발생.</li>
                        <li><strong>최종 상태:</strong> 일정 수준에서 안정화되며 낮은 손실 값 유지.</li>
                    </ul>
                </li>
                <li><strong>훈련과 테스트 손실 비교:</strong>
                    <ul>
                        <li>초반: 훈련 손실과 테스트 손실이 비슷한 경향을 보임.</li>
                        <li>후반: 훈련 손실은 계속 감소하지만 테스트 손실은 약간의 변동 → 과적합 가능성.</li>
                    </ul>
                </li>
            </ul>
            <h4> 결론</h4>
            <ul>
                <li><strong>훈련 손실:</strong> 모델이 훈련 데이터에 점점 더 적응하여 손실이 꾸준히 감소.</li>
                <li><strong>테스트 손실:</strong> 초반에는 개선되지만, 후반에 변동 → 모델이 과적합되지 않도록 추가적인 조치 필요 (예: 더 많은 데이터, 규제 기법 등).</li>
                <li><strong>그래프:</strong> 학습 및 성능의 추이를 확인하고, 과적합 여부를 판단하는 데 유용함.</li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/16.png" alt="Deeplearning 열 여섯 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 정확도 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 2], 'b', label='Train Accuracy')</code></li>
                        <li><code>history[:, 0]</code>: 에포크 값 (x축).</li>
                        <li><code>history[:, 2]</code>: 훈련 데이터 정확도 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train Accuracy'</code>: 범례에 "Train Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 4], 'k', label='Test Accuracy')</code></li>
                        <li><code>history[:, 4]</code>: 테스트 데이터 정확도 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test Accuracy'</code>: 범례에 "Test Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Accuracy')</code>: y축 이름 설정 (정확도).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>            
            <h4> 그래프 해석</h4>
            <ul>
                <li><strong>훈련 정확도 (Train Accuracy):</strong>
                    <ul>
                        <li><strong>초기 상태:</strong> 낮은 정확도로 시작.</li>
                        <li><strong>진행 상황:</strong> 에포크가 진행될수록 정확도가 꾸준히 상승.</li>
                        <li><strong>최종 상태:</strong> 약 75%의 높은 정확도에 도달, 모델이 훈련 데이터에 잘 적응했음을 의미.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도 (Test Accuracy):</strong>
                    <ul>
                        <li><strong>초기 상태:</strong> 훈련 정확도와 유사하게 시작.</li>
                        <li><strong>진행 상황:</strong> 초반에 빠르게 상승, 이후 안정화되며 약간의 변동 발생.</li>
                        <li><strong>최종 상태:</strong> 약 65%의 정확도에 도달, 훈련 데이터에 비해 약간 낮음.</li>
                    </ul>
                </li>
                <li><strong>훈련과 테스트 정확도 비교:</strong>
                    <ul>
                        <li>훈련 데이터에 비해 테스트 데이터에서 낮은 성능을 보임.</li>
                        <li>이는 과적합 가능성을 나타냄.</li>
                        <li>그러나 큰 차이가 없으므로, 모델의 일반화 성능이 나쁘지는 않음.</li>
                    </ul>
                </li>
            </ul>            
            <h4> 결론</h4>
            <ul>
                <li><strong>훈련 정확도:</strong> 모델이 훈련 데이터에 적응하여 정확도가 꾸준히 상승.</li>
                <li><strong>테스트 정확도:</strong> 안정적인 정확도를 유지하며, 모델이 어느 정도 일반화되었음을 확인.</li>
                <li><strong>제안:</strong> 테스트 데이터 성능을 더욱 향상시키기 위해 추가 데이터, 규제 기법 또는 Dropout 적용을 고려.</li>
                <li><strong>그래프:</strong> 학습 및 모델의 진행 상황과 일반화 성능을 시각적으로 확인할 수 있음.</li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/17.png" alt="Deeplearning 열 일곱 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong><code>transforms.ToTensor()</code></strong>
                    <ul>
                        <li>이미지를 PyTorch 텐서 형식으로 변환.</li>
                        <li>픽셀 값을 <code>[0, 255]</code>에서 <code>[0.0, 1.0]</code> 범위로 정규화.</li>
                    </ul>
                </li>
                <li><strong><code>transforms.RandomHorizontalFlip(p=0.5)</code></strong>
                    <ul>
                        <li>50% 확률로 이미지를 수평으로 뒤집음.</li>
                    </ul>
                </li>
                <li><strong><code>transforms.RandomVerticalFlip(p=0.5)</code></strong>
                    <ul>
                        <li>50% 확률로 이미지를 수직으로 뒤집음.</li>
                    </ul>
                </li>
                <li><strong><code>transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.5, 2))</code></strong>
                    <ul>
                        <li>이미지의 일부를 무작위로 지움.</li>
                        <li><code>scale:</code> 지워지는 영역의 크기 범위.</li>
                        <li><code>ratio:</code> 지워지는 영역의 너비와 높이 비율.</li>
                    </ul>
                </li>
                <li><strong><code>transforms.RandomResizedCrop((32, 32), scale=(0.1, 1), ratio=(0.5, 2))</code></strong>
                    <ul>
                        <li>이미지를 무작위로 자르고 지정된 크기(<code>32x32</code>)로 재조정.</li>
                        <li><code>scale:</code> 자른 이미지 크기 비율.</li>
                        <li><code>ratio:</code> 자른 이미지의 너비와 높이 비율.</li>
                    </ul>
                </li>
                <li><strong><code>transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)</code></strong>
                    <ul>
                        <li>이미지의 밝기, 대비, 채도, 색조를 랜덤하게 조정.</li>
                        <li>모델이 다양한 색상 변화에 적응할 수 있도록 지원.</li>
                    </ul>
                </li>
            </ol>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/18.png" alt="Deeplearning 열 여덟 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 손실 (Train error):</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 1], 'b', label='Train error')</code></li>                     
                        <li><code>history[:, 1]</code>: 훈련 데이터 손실 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train error'</code>: 범례에 "Train error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 손실 (Test error):</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 3], 'k', label='Test error')</code></li>
                        <li><code>history[:, 3]</code>: 테스트 데이터 손실 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test error'</code>: 범례에 "Test error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Loss')</code>: y축 이름 설정 (손실 값).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>       
            <h4> 그래프 해석</h4>
            <ul>
                <li><strong>훈련 손실 (Train error):</strong>
                    <ul>
                        <li>초기 에포크에서 손실이 높게 시작.</li>
                        <li>에포크가 진행됨에 따라 꾸준히 감소.</li>
                        <li>모델이 훈련 데이터에 점점 더 잘 적응하고 있음을 나타냄.</li>
                    </ul>
                </li>
                <li><strong>테스트 손실 (Test error):</strong>
                    <ul>
                        <li>초기에는 높은 손실 값에서 유사하게 감소.</li>
                        <li>이후 안정적으로 감소하여 약간의 변동 발생.</li>
                        <li>테스트 손실은 안정적이며 과적합 가능성을 낮게 보임.</li>
                    </ul>
                </li>
                <li><strong>훈련과 테스트 손실 비교:</strong>
                    <ul>
                        <li>훈련 손실이 테스트 손실보다 더 낮음.</li>
                        <li>테스트 손실도 안정적이므로 과적합 가능성은 낮아 보임.</li>
                    </ul>
                </li>
            </ul>
            <h4> 결론</h4>
            <ul>
                <li><strong>훈련 손실:</strong> 꾸준히 감소하며, 모델이 훈련 데이터에 잘 적응.</li>
                <li><strong>테스트 손실:</strong> 낮은 손실 값에서 안정적, 모델이 데이터를 잘 일반화함.</li>
                <li><strong>평가:</strong> 훈련 손실은 작아도 테스트 손실이 과도하지 않으며 안정적인 성능을 보임.</li>
                <li>그래프는 데이터 증강과 규제 기법이 효과적으로 작용했음을 보여줌.</li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/19.png" alt="Deeplearning 열 아홉 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 정확도 (Train Accuracy):</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 2], 'b', label='Train Accuracy')</code></li>
                        <li><code>history[:, 0]</code>: 에포크 값 (x축).</li>
                        <li><code>history[:, 2]</code>: 훈련 데이터 정확도 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train Accuracy'</code>: 범례에 "Train Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도 (Test Accuracy):</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 4], 'k', label='Test Accuracy')</code></li>
                        <li><code>history[:, 4]</code>: 테스트 데이터 정확도 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test Accuracy'</code>: 범례에 "Test Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Accuracy')</code>: y축 이름 설정 (정확도).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>
            <h4> 그래프 해석</h4>
            <ul>
                <li><strong>훈련 정확도 (Train Accuracy):</strong>
                    <ul>
                        <li><strong>초기 상태:</strong> 낮은 정확도로 시작, 에포크 증가에 따라 꾸준히 상승.</li>
                        <li><strong>최종 상태:</strong> 약 75%에 도달, 모델이 훈련 데이터에 잘 적응했음을 나타냄.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도 (Test Accuracy):</strong>
                    <ul>
                        <li><strong>초기 상태:</strong> 훈련 정확도와 유사한 상승 곡선을 보임.</li>
                        <li><strong>최종 상태:</strong> 안정화되어 약 70%에 도달.</li>
                        <li>테스트 정확도가 훈련 정확도에 비해 약간 낮지만 큰 차이는 없음.</li>
                    </ul>
                </li>
                <li><strong>훈련과 테스트 정확도 비교:</strong>
                    <ul>
                        <li>두 곡선이 유사한 경향을 보이며, 훈련 정확도가 약간 더 높음.</li>
                        <li>테스트 데이터에서 과적합이 거의 없음을 나타냄.</li>
                    </ul>
                </li>
            </ul>
            <h4> 결론</h4>
            <ul>
                <li><strong>훈련 정확도:</strong> 모델이 훈련 데이터에서 높은 정확도를 달성.</li>
                <li><strong>테스트 정확도:</strong> 모델이 테스트 데이터에서도 안정적이고 높은 성능을 보임.</li>
                <li><strong>모델 평가:</strong>
                    <ul>
                        <li>훈련 데이터와 테스트 데이터 모두에서 성능이 안정적이며 과적합 위험이 낮음.</li>
                        <li>모델의 일반화 능력을 잘 유지하고 있음을 확인.</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
</body>
</html>
