<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>합성곱 신경망과 튜닝 기법(CNN)</title>
    <link rel="stylesheet" href="style-Deeplearning5.css">
</head>
<body>
    <div class="content-container">
        <!-- 제목 -->
        <h1 class="left"> 합성곱 신경망과 튜닝 기법 </h1>

        <!-- 합성곱 신경망 실습 -->
        <div class="description-section">
            <h2> 라이브러리와 GPU 할당 </h2>
            <div class="image-section.left">
              <img src="Deep learning5 images/1.png" alt="라이브러리와 GPU 할당" class="deep-learning-image">
            </div>
        </div>

      <!-- CIFAR10 데이터로 합성곱 신경망 적용 -->
        <div class="description-section">
            <h2> CIFAR10 데이터로 합성곱 신경망 적용 </h2>
            <div class="image-section.left">
              <img src="Deep learning5 images/2.png" alt="CIFAR10 데이터로 합성곱 신경망 적용" class="deep-learning-image">
            </div>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/3.png" alt="Deeplearning 세 번째 이미지" class="opencv-image">
        </div>
      <div class="description-section">
            <ol>
                <li><code>len(train_set)</code><br>
                    훈련 데이터셋에 50,000개의 이미지가 포함되어 있다는 것을 의미합니다.
                </li>
                <li><code>len(test_set)</code><br>
                    테스트 데이터셋에는 10,000개의 이미지가 포함되어 있다는 것을 보여줍니다.
                </li>
                <li><code>classes = train_set.classes</code><br>
                    데이터셋에 포함된 10개의 클래스는 다음과 같습니다(airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)
                </li>
                <li><code>len(classes)</code><br>
                    총 10개의 클래스가 존재한다는 것을 확인할 수 있습니다.
                </li>
            </ol>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/4.png" alt="Deeplearning 네 번째 이미지" class="opencv-image">
        </div>
      <div class="description-section">
            <ol>
                <li><code>batch_size = 128</code><br>
                  배치 크기를 설정하여 CNN 학습 시 한 번에 처리할 데이터 양을 지정합니다.<br>
                  이는 모델 학습과 추론의 효율성을 높이고 메모리 사용을 최적화합니다.
                </li>
                <li><code>DataLoader</code><br>
                  CNN 학습에 필요한 데이터 로딩 및 배치 구성을 담당합니다.<br>
                  <code>shuffle=True</code>는 데이터 순서를 무작위로 섞어 모델이 데이터를 고르게 학습하도록 합니다(훈련 데이터에 중요).
                </li>
                <li><code>images.shape</code><br>
                  <code>(128, 3, 32, 32)</code> → CNN 모델에 입력되는 데이터 형식.<br>
                  -128개의 이미지(batch size).<br>
                  -각 이미지가 3채널(RGB)이고 크기는 32x32.<br>
                  CNN은 이 형식의 데이터를 입력으로 받아 특징을 추출합니다.
                </li>
                <li><code>len(classes)</code><br>
                    총 10개의 클래스가 존재한다는 것을 확인할 수 있습니다.
                </li>
            </ol>
      </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/5.png" alt="Deeplearning 다섯 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><code>plt.figure(figsize=(10, 3))</code><br>
                  출력 이미지 전체의 크기를 설정합니다. 너비는 10, 높이는 3입니다.
                </li>
                <li><code>for i in range(20)</code><br>
                  처음 20개의 이미지를 반복하며 출력합니다.
                </li>
                <li><codeax = plt.subplot(2, 10, i + 1)</code><br>
                  서브플롯(subplot)을 생성합니다.<br>
                    2행 10열의 그리드에서 현재 위치(i + 1)에 이미지를 그립니다.
                </li>
                <li><code>image, label = train_set[i]</code><br>
                    CIFAR-10 데이터셋에서 이미지<code>(image)</code>와 해당 레이블<code>(label)</code>을 가져옵니다.
                </li>
                <li><code>plt.imshow(np.transpose(image, (1, 2, 0)))</code><br>
                    이미지를 출력합니다.<br>
                    PyTorch 데이터는 <code>(채널, 높이, 너비)</code> 형식이므로 <code>np.transpose</code>를 사용해 <code>(높이, 너비, 채널)</code>로 변환해야 <code>matplotlib</code>에서 제대로 표시됩니다.
                </li>
                <li><code>ax.set_title(f'{classes[label]}')</code><br>
                이미지의 레이블(클래스 이름)을 제목으로 표시합니다.
                </li>
                <li><code>ax.get_xaxis().set_visible(False)와 ax.get_yaxis().set_visible(False)</code><br>
                x축과 y축을 숨겨 시각적으로 깔끔하게 만듭니다.
                </li>
                <li><code>plt.show()</code><br>
                작성된 모든 플롯을 출력합니다.
                </li>
            </ol>
      </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/6.png" alt="Deeplearning 여섯 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><code>CNN1 클래스 정의</code><br>
                    CNN1 클래스는 PyTorch의 <code>nn.Module</code>을 상속받아 간단한 CNN 모델을 정의합니다.
                </li>
                <li><code>__init__ 메서드</code><br>
                    네트워크의 층을 정의합니다.
                    <ul>
                        <li><code>self.layer1</code>:<br>
                            합성곱 (<code>nn.Conv2d</code>) → ReLU → MaxPooling으로 구성된 합성곱 블록.
                            <ul>
                                <li>입력 채널: 3 (RGB 이미지), 출력 채널: 32.</li>
                            </ul>
                        </li>
                        <li><code>self.l1</code>:<br>
                            완전 연결층 (<code>nn.Linear</code>)으로, 입력 크기: <code>32 * 16 * 16</code>, 출력 크기: 50.
                        </li>
                        <li><code>self.l2</code>:<br>
                            완전 연결층 (<code>nn.Linear</code>)으로, 입력 크기: 50, 출력 크기: 10 (클래스 수).
                        </li>
                    </ul>
                </li>
                <li><code>forward 메서드</code><br>
                    데이터의 순차적인 흐름을 정의합니다:
                    <ul>
                        <li><code>self.layer1(x)</code>: 합성곱과 맥스풀링 처리.</li>
                        <li><code>x.view(x.size(0), -1)</code>: 출력을 평탄화 (<code>flatten</code>).</li>
                        <li><code>self.l1(x) → self.relu(x) → self.l2(x)</code>: 완전 연결층과 활성화 함수 적용.</li>
                    </ul>
                    최종 출력: 클래스별 점수.
                </li>
            </ol>
        </div>

         <div class="image-section.left">
            <img src="Deep learning5 images/7.png" alt="Deeplearning 일곱 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><code>torch.cuda.manual_seed(123)</code><br>
                    CUDA 연산에서 난수 생성기의 시드를 고정하여 결과를 재현 가능하게 만듭니다.
                </li>
                <li><code>model = CNN1()</code><br>
                    이전에 정의한 CNN1 모델을 인스턴스화합니다.
                </li>
                <li><code>model.to(device)</code><br>
                    모델을 <code>device</code>로 이동시킵니다. (예: GPU 또는 CPU)
                </li>
                <li><code>lr = 1e-3</code><br>
                    학습률(<code>learning rate</code>)을 0.001로 설정합니다.
                </li>
                <li><code>criterion = nn.CrossEntropyLoss()</code><br>
                    손실 함수로 교차 엔트로피 손실을 사용합니다.
                    <ul>
                        <li>분류 문제에서 주로 사용되며, 모델 출력(클래스 확률)과 실제 레이블 간 차이를 계산합니다.</li>
                    </ul>
                </li>
                <li><code>optimizer = torch.optim.Adam(model.parameters(), lr=lr)</code><br>
                    옵티마이저로 Adam을 사용합니다.
                    <ul>
                        <li>모델의 가중치를 학습하기 위해 설정된 학습률(<code>lr=1e-3</code>)로 매개변수를 업데이트합니다.</li>
                    </ul>
                </li>
                <li><code>history = np.zeros((0, 5))</code><br>
                    학습 기록을 저장할 빈 배열을 생성합니다.
                    <ul>
                        <li>5개의 열은 학습/검증 손실 및 정확도를 저장하는 용도로 보입니다.</li>
                    </ul>
                </li>
            </ol>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/8.png" alt="Deeplearning 여덟 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 단계</strong>
                    <ul>
                        <li><code>for images, labels in tqdm(train_loader):</code><br>
                            <strong>train_loader</strong>에서 배치 데이터를 가져옵니다.<br>
                            <strong>tqdm:</strong> 학습 진행 상황을 시각적으로 표시.
                        </li>
                        <li><code>inputs, labels = images.to(device), labels.to(device)</code><br>
                            데이터를 GPU/CPU로 전송합니다.
                        </li>
                        <li><code>optimizer.zero_grad()</code><br>
                            그래디언트를 초기화합니다.
                        </li>
                        <li><code>outputs = model(inputs)</code><br>
                            순전파(<strong>forward pass</strong>)를 통해 예측값 계산.
                        </li>
                        <li><code>loss_model = criterion(outputs, labels)</code><br>
                            손실 함수(<strong>criterion</strong>)를 사용해 손실 계산.
                        </li>
                        <li><code>loss_model.backward()</code><br>
                            역전파(<strong>backward pass</strong>)로 그래디언트 계산.
                        </li>
                        <li><code>optimizer.step()</code><br>
                            옵티마이저로 가중치 업데이트.
                        </li>
                        <li><code>train_loss += loss_model.item()</code><br>
                            현재 배치의 손실 값 누적.
                        </li>
                        <li><code>train_acc += (pred == labels).sum().item()</code><br>
                            예측값과 실제값 비교 후 정확도 계산.
                        </li>
                    </ul>
                </li>
                <li><strong>테스트 단계</strong>
                    <ul>
                        <li><code>for images_test, labels_test in test_loader:</code><br>
                            테스트 데이터 배치를 가져옵니다.
                        </li>
                        <li><code>outputs_test = model(inputs_test)</code><br>
                            테스트 데이터에서 모델 예측값 계산.
                        </li>
                        <li><code>loss_test_model = criterion(outputs_test, labels_test)</code><br>
                            테스트 손실 계산.
                        </li>
                        <li><code>pred_test = outputs_test.max(axis=1)[1]</code><br>
                            각 클래스 확률 중 가장 높은 클래스 예측값 반환.
                        </li>
                        <li><code>test_loss += loss_test_model.item()</code><br>
                            테스트 데이터 손실 값 누적.
                        </li>
                        <li><code>test_acc += (pred_test == labels_test).sum().item()</code><br>
                            테스트 정확도 계산.
                        </li>
                    </ul>
                </li>
                <li><strong>에포크별 결과 계산</strong>
                    <ul>
                        <li><code>train_loss /= n_train</code> & <code>test_loss /= n_test</code><br>
                            학습/테스트 손실 평균 계산.
                        </li>
                        <li><code>train_acc /= n_train</code> & <code>test_acc /= n_test</code><br>
                            학습/테스트 정확도 비율 계산.
                        </li>
                    </ul>
                </li>
                <li><strong>결과 출력 및 기록</strong>
                    <ul>
                        <li><code>print(f'Epoch {epoch+1}/{num_epochs}, ...')</code><br>
                            각 에포크별 학습/테스트 손실 및 정확도 출력.
                        </li>
                        <li><code>item = np.array([...])</code><br>
                            결과를 배열로 저장.
                        </li>
                        <li><code>history = np.vstack([history, item])</code><br>
                            기록(<strong>history</strong>)에 저장.
                        </li>
                    </ul>
                </li>
            </ol>
        </div>
        <div class="description-section">
            <h4>핵심 포인트</h4>
            <ul>
                <li><strong>훈련 단계:</strong>
                    <ul>
                        <li>데이터 로드 → 순전파 → 손실 계산 → 역전파 → 가중치 업데이트.</li>
                    </ul>
                </li>
                <li><strong>테스트 단계:</strong>
                    <ul>
                        <li>데이터 로드 → 예측 → 손실 및 정확도 평가.</li>
                    </ul>
                </li>
                <li><strong>결과 출력:</strong>
                    <ul>
                        <li>에포크별 손실과 정확도를 기록해 모델 학습 상태를 모니터링.</li>
                    </ul>
                </li>
            </ul>
            <p><strong>결론:</strong> 학습과 테스트 단계를 반복하며, 모델 성능(손실 및 정확도)을 추적하고 출력합니다.</p>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/9.png" alt="Deeplearning 아홉 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol><li><code>history</code>:
                <ul>
                    <li>학습 과정에서 저장된 손실과 정확도 데이터를 담고 있는 배열.</li>
                    <li>형식: [<code>에포크, train_loss, train_acc, test_loss, test_acc</code>]</li>
                </ul>
            </li>
                <li>초기 상태 출력:
                    <ul>
                        <li><code>print(f'초기 손실: 손실 = {history[0, 3]:.5f} ...')</code>: 첫 번째 에포크의 테스트 손실과 정확도 출력.</li>
                        <li><code>history[0, 3]</code>: 첫 번째 에포크의 테스트 손실.</li>
                        <li><code>history[0, 4]</code>: 첫 번째 에포크의 테스트 정확도.</li>
                    </ul>
                </li>
                <li>최종 상태 출력:
                    <ul>
                        <li><code>print(f'최종 손실: 손실 = {history[-1, 3]:.5f} ...')</code>: 마지막 에포크의 테스트 손실과 정확도 출력.</li>
                        <li><code>history[-1, 3]</code>: 마지막 에포크의 테스트 손실.</li>
                        <li><code>history[-1, 4]</code>: 마지막 에포크의 테스트 정확도.</li>
                    </ul>
                </li>
            </ol>

            <h2>결과</h2>
            <ul>
                <li><strong>초기 상태:</strong>
                    <ul>
                        <li><strong>손실:</strong> 0.81137</li>
                        <li><strong>정확도:</strong> 0.49544 (약 49.54%)</li>
                        <li>모델이 학습 초기에는 낮은 정확도를 보임.</li>
                    </ul>
                </li>
                <li><strong>최종 상태:</strong>
                    <ul>
                        <li><strong>손실:</strong> 0.08832</li>
                        <li><strong>정확도:</strong> 0.64618 (약 64.61%)</li>
                        <li>학습 후 모델의 정확도가 크게 향상됨.</li>
                    </ul>
                </li>
            </ul>
        </div>


        <div class="image-section.left">
            <img src="Deep learning5 images/10.png" alt="Deeplearning 열 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 손실 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 1], 'b', label='Train error')</code></li>
                        <li><code>history[:, 0]</code>: 에포크 값 (x축).</li>
                        <li><code>history[:, 1]</code>: 훈련 데이터 손실 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train error'</code>: 범례에 "Train error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 손실 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 3], 'k', label='Test error')</code></li>
                        <li><code>history[:, 3]</code>: 테스트 데이터 손실 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test error'</code>: 범례에 "Test error"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Loss')</code>: y축 이름 설정 (손실 값).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>
            
            <h4>그래프 해석</h4>
            <ul>
                <li><strong>훈련 손실:</strong> 에포크가 증가함에 따라 손실 값이 꾸준히 감소.<br>
                    이는 모델이 훈련 데이터에 대해 점점 더 잘 학습하고 있음을 나타냄.</li>
                <li><strong>테스트 손실:</strong> 초기에 감소하다가 에포크가 진행됨에 따라 약간의 변동이 있음.<br>
                    모델이 테스트 데이터에도 적절히 학습했음을 보여줌.</li>
            </ul>
        </div>

        <div class="image-section.left">
            <img src="Deep learning5 images/11.png" alt="Deeplearning 열 한 번째 이미지" class="opencv-image">
        </div>
        <div class="description-section">
            <ol>
                <li><strong>훈련 정확도 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 2], 'b', label='Train Accuracy')</code></li>
                        <li><code>history[:, 0]</code>: 에포크 값 (x축).</li>
                        <li><code>history[:, 2]</code>: 훈련 데이터 정확도 (y축).</li>
                        <li><code>'b'</code>: 파란색 선으로 표시.</li>
                        <li><code>label='Train Accuracy'</code>: 범례에 "Train Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도 출력:</strong>
                    <ul>
                        <li><code>plt.plot(history[:, 0], history[:, 4], 'k', label='Test Accuracy')</code></li>
                        <li><code>history[:, 4]</code>: 테스트 데이터 정확도 (y축).</li>
                        <li><code>'k'</code>: 검은색 선으로 표시.</li>
                        <li><code>label='Test Accuracy'</code>: 범례에 "Test Accuracy"로 표시.</li>
                    </ul>
                </li>
                <li><strong>축 및 범례 설정:</strong>
                    <ul>
                        <li><code>plt.xlabel('Epoch')</code>: x축 이름 설정 (에포크: 학습 반복 횟수).</li>
                        <li><code>plt.ylabel('Accuracy')</code>: y축 이름 설정 (정확도).</li>
                        <li><code>plt.legend()</code>: 범례 추가.</li>
                        <li><code>plt.show()</code>: 그래프 출력.</li>
                    </ul>
                </li>
            </ol>
            
            <h4>그래프 해석</h4>
            <ul>
                <li><strong>훈련 정확도:</strong>
                    <ul>
                        <li>초기 정확도에서 빠르게 상승.</li>
                        <li>에포크가 증가함에 따라 정확도가 약 75%에 도달.</li>
                        <li>이는 모델이 훈련 데이터에 대해 점진적으로 학습했음을 보여줌.</li>
                    </ul>
                </li>
                <li><strong>테스트 정확도:</strong>
                    <ul>
                        <li>처음에 약간의 변동이 있었으나, 안정적으로 증가.</li>
                        <li>최종적으로 테스트 정확도가 약 65%에 도달.</li>
                        <li>훈련 정확도와 테스트 정확도 간 간격이 좁아져, 과적합의 위험이 낮음을 나타냄.</li>
                    </ul>
                </li>
            </ul>
        </div>
        
    </div>
</body>
</html>
