<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>합성곱 신경망과 튜닝 기법(CNN)</title>
    <link rel="stylesheet" href="style-Deeplearning6.css">
</head>
<body>
  <div class="content-container">
        <!-- 제목 -->
        <h1 class="left"> 전이학습과 순환신경망(RNN) </h1>

        <!-- 전이학습과 순환신경망(RNN) -->
        <div class="description-section">
            <h2> CNN 전이학습 </h2>
            <div class="image-section.left">
              <img src="Deep learning6 images/1.png" alt="CNN 전이학습" class="deep-learning-image">
            </div>
        </div>
    <div class="description-section">
      <ul>
        <li>일반적으로 합성곱 신경망 기반의 딥러닝 모델을 제대로 훈련시키려면 많은 양의 데이터가 필요함.</li>
        <li>불행히도 충분한 큰 데이터셋을 얻는 것은 쉽지 않음.</li>
        <li>큰 데이터셋을 확보하려면 많은 돈과 시간이 필요하기 때문임.</li>
        <li>이러한 현실적인 어려움을 해결한 것이 전이 학습(transfer learning).</li>
        <li>전이 학습은 이미지넷(ImageNet)처럼 아주 큰 데이터셋에서 사전 훈련된 모델의 가중치를 가져와 우리가 해결하려는 과제에 맞게 보정해서 사용하는 것을 의미.</li>
        <li>이런 아주 큰 데이터셋을 사용하여 훈련된 모델을 사전 훈련된 모델(네트워크)라고 함.</li>
        <li>결과적으로 비교적 적은 수의 데이터를 가지고도 우리가 원하는 과제를 해결할 수 있음.</li>
      </ul>
    </div>    

      <div class="image-section.left">
          <img src="Deep learning6 images/2.png" alt="CNN 특성 추출 기법" class="deep-learning-image">
      </div>
      <div class="description-section">
          <h4>특성 추출 기법</h4>
          <ul>
              <li><strong>특성 추출(feature extractor):</strong> ImageNet 데이터셋으로 사전 훈련된 모델을 가져온 후 마지막에 완전연결층 부분만 새로 만듦.</li>
              <li>
                  학습할 때는 마지막 완전연결층(이미지의 카테고리를 결정하는 부분)만 학습하고 나머지 계층들은 학습되지 않도록 함.
              </li>
              <li>
                  특성 추출은 이미지 분류를 위해 두 부분으로 구성:
                  <ul>
                      <li><strong>합성곱층:</strong> 합성곱과 풀링층으로 구성.</li>
                      <li><strong>데이터 분류기(완전연결층):</strong> 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류하는 부분.</li>
                  </ul>
              </li>
              <li>
            사전 훈련된 네트워크의 합성곱층(가중치 고정)에 새로운 데이터로 증강시키고, 그 출력값 데이터를 분류기에 훈련시킴.
              </li>
          </ul>
      </div>

      <div class="image-section.left">
          <img src="Deep learning6 images/3.png" alt="3" class="deep-learning-image">
      </div>
      <div class="description-section">
          <p>라이브러리와 GPU 할당</p>
      </div>

      <div class="image-section.left">
          <img src="Deep learning6 images/4.png" alt="4" class="deep-learning-image">
      </div>
      <div class="description-section">
          <ul>
              <li><strong>학습 데이터:</strong>
                  <ul>
                      <li><strong>데이터 증강:</strong> 크기 조정, 수평 뒤집기, 랜덤 영역 삭제.</li>
                      <li><strong>정규화:</strong> 데이터 값을 평균과 표준편차로 표준화.</li>
                      <li><strong>데이터 로더:</strong> 배치 크기=50, 데이터 순서를 섞음.</li>
                  </ul>
              </li>
              <li><strong>검증 데이터:</strong>
                  <ul>
                      <li><strong>데이터 증강 없음:</strong> 정규화만 수행.</li>
                      <li><strong>데이터 로더:</strong> 배치 크기=50, 데이터 순서를 유지.</li>
                  </ul>
              </li>
          </ul>
      </div>

      <div class="image-section.left">
          <img src="Deep learning6 images/5.png" alt="5" class="deep-learning-image">
      </div>
      <div class="description-section">
          <ul>
              <li><code>weights='IMAGENET1K_V1'</code>:
                  <ul>
                      <li>PyTorch 최신 버전에서는 <code>pretrained=True</code> 대신 <code>weights</code> 매개변수를 사용.</li>
                      <li><code>'IMAGENET1K_V1'</code>: ImageNet 데이터셋으로 학습된 ResNet-18 모델의 가중치를 불러옴.</li>
                  </ul>
              </li>
          </ul>
      </div>      
      <div class="image-section.left">
          <img src="Deep learning6 images/6.png" alt="6" class="deep-learning-image">
      </div>
      <div class="description-section">
          <h4>1. 합성곱 층 (Conv2d):</h4>
          <pre>Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</pre>
          <ul>
              <li><strong>합성곱 연산을 수행하는 층.</strong></li>
              <li>입력 채널=128, 출력 채널=128, 커널 크기=3x3.</li>
              <li><code>stride=(1, 1)</code>: 필터가 1픽셀씩 이동.</li>
              <li><code>padding=(1, 1)</code>: 입력 이미지 가장자리에 패딩을 추가하여 출력 크기를 유지.</li>
              <li><code>bias=False</code>: 바이어스를 BatchNorm과 함께 사용하지 않음.</li>
          </ul>
          
          <h4>2. 배치 정규화 (BatchNorm2d):</h4>
          <pre>BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</pre>
          <ul>
              <li>채널별로 데이터를 정규화하여 학습 안정성 향상.</li>
              <li><code>eps</code>: 수치 안정성을 위해 추가되는 작은 값.</li>
              <li><code>momentum</code>: 이동 평균 계산 시 사용.</li>
              <li><code>affine=True</code>: 학습 가능한 스케일링과 이동 매개변수 사용.</li>
          </ul>
          
          <h4>3. 적용형 풀링층 (AdaptiveAvgPool2d):</h4>
          <pre>AdaptiveAvgPool2d(output_size=(1, 1))</pre>
          <ul>
              <li>입력 특징 맵의 크기를 1x1로 변환.</li>
              <li>입력 크기에 상관없이 고정된 출력 크기를 생성.</li>
          </ul>
          
          <h4>4. 완전 연결층 (Fully Connected):</h4>        
          <code>Linear(in_features=512, out_features=1000, bias=True)</code>
          <ul>
              <li>입력 특성 수=512, 출력 클래스 수=1000 (ImageNet 클래스 개수).</li>
              <li>모델의 최종 출력층으로, 각 클래스에 대한 점수 생성.</li>
          </ul>
      </div>   

      <div class="image-section.left">
          <img src="Deep learning7 images/6.png" alt="7" class="deep-learning-image">
      </div><div class="description-section">
          <h4>1. 라이브러리 설치 및 임포트</h4>
          <pre>!pip install torchinfo | tail -n 1</pre>
          <ul>
              <li><strong>torchinfo:</strong> PyTorch 모델의 구조를 요약해서 출력하는 라이브러리.</li>
              <li><strong>tail -n 1:</strong> 설치 완료 메시지 한 줄만 출력.</li>
          </ul>
          <pre>from torchinfo import summary</pre>
          <ul>
              <li><code>torchinfo</code>의 <code>summary</code> 함수로 모델 구조를 시각화.</li>
          </ul>
          
          <h4>2. 모델 이동</h4>
          <pre>net = net.to(device)</pre>
          <ul>
              <li>모델(<code>net</code>)을 지정된 장치(<code>device</code>, GPU 또는 CPU)로 이동.</li>
          </ul>
          
          <h4>3. 모델 구조 요약</h4>
          <pre>summary(net, (128, 3, 112, 112))</pre>
          <ul>
              <li><code>net:</code> 모델 객체.</li>
              <li><code>(128, 3, 112, 112):</code> 입력 데이터 크기.
                  <ul>
                      <li>배치 크기=128, 채널 수=3 (RGB 이미지), 이미지 크기=112x112.</li>
                  </ul>
              </li>
              <li>모델 구조와 각 층의 출력 크기 및 매개변수 수를 요약해서 출력.</li>
          </ul>
          
          <h4>4. 출력 내용 해석</h4>
          <ul>
              <li><strong>Column 1: Layer</strong>
                  <ul>
                      <li>모델의 각 계층을 계층 깊이(<code>depth-idx</code>)와 함께 나열.</li>
                      <li>주요 계층:
                          <ul>
                              <li><code>Conv2d:</code> 합성곱 계층.</li>
                              <li><code>BatchNorm2d:</code> 배치 정규화 계층.</li>
                              <li><code>ReLU:</code> 활성화 함수 계층.</li>
                              <li><code>MaxPool2d:</code> 맥스 풀링 계층.</li>
                              <li><code>Sequential:</code> 여러 계층이 연속적으로 연결된 블록.</li>
                              <li><code>BasicBlock:</code> ResNet의 기본 구성 요소.</li>
                          </ul>
                      </li>
                  </ul>
              </li>
              <li><strong>Column 2: Output Shape</strong>
                  <ul>
                      <li>각 계층의 출력 텐서 크기:
                          <ul>
                              <li>예: <code>[128, 64, 56, 56]</code></li>
                              <li>배치 크기=128, 채널=64, 출력 이미지 크기=56x56.</li>
                          </ul>
                      
                      </li>
                      <li>계층마다 입력 데이터의 크기가 점진적으로 변환됨.</li>
                  </ul>
              </li>
              <li><strong>Column 3: Param #</strong>
                  <ul>
                      <li>각 계층의 학습 가능한 매개변수(Parameter) 개수.
                          <ul>
                              <li>예: <code>Conv2d 1-1:</code> 9,408개의 매개변수.</li>
                              <li><code>BatchNorm2d 1-2:</code> 128개의 매개변수.</li>
                          </ul>
                      </li>
                  </ul>
              </li>
          </ul>
      </div>
</body>
</html>
