<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GAN</title>
    <link rel="stylesheet" href="style-Deeplearning10.css">
</head>
<body>
  <div class="content-container">
    <!-- 제목 -->
      <h1 class="left"> PINN </h1>

    <div class="description-section">
      <div class="image-section.left">
        <img src="Deep learning10 images/1.png" alt="1" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>미분방정식 정의:</strong>
          <ul>
            <li>한 개 이상의 종속변수와 독립변수에 대한 미분 도함수를 포함하는 방정식.</li>
          </ul>
        </li>
        <li>
          <strong>분류 기준:</strong>
          <ul>
            <li>
              <strong>계수:</strong>
              <ul>
                <li>1계 미분방정식: 종속변수의 1차 미분만 포함.</li>
                <li>고계 미분방정식: 2차 이상의 고차 미분 포함.</li>
              </ul>
            </li>
            <li>
              <strong>선형성:</strong>
              <ul>
                <li>선형 미분방정식: 종속변수와 그 미분항이 선형적으로 나타나는 경우.</li>
                <li>비선형 미분방정식: 비선형 항을 포함하는 경우.</li>
              </ul>
            </li>
            <li>
              <strong>유형:</strong>
              <ul>
                <li>ODE(상미분방정식): 하나의 독립변수에 대해 정의된 미분방정식.</li>
                <li>PDE(편미분방정식): 두 개 이상의 독립변수에 대해 정의된 미분방정식.</li>
              </ul>
            </li>
          </ul>
        </li>
      </ol>

      <ul>
        <li>
          <strong>상미분방정식 (Ordinary Differential Equation, ODE):</strong>
          <ul>
            <li>미분방정식에서 구하려는 함수가 하나의 독립변수만을 가지는 경우.</li>
            <li>예<br>
              <img src="Deep learning10 images/2.png" alt="2">
              이는 <i>t</i>라는 하나의 독립변수에 대한 종속변수 <i>y(t)</i>의 변화를 나타냅니다.
            </li>
          </ul>
        </li>
        <li>
          <strong>편미분방정식 (Partial Differential Equation, PDE):</strong>
          <ul>
            <li>구하려는 함수가 여러 개의 독립변수로 구성되며, 그 함수의 편미분을 포함하는 경우.</li>
            <li>예<br>
              <img src="Deep learning10 images/3.png" alt="3">
              이는 <i>t</i>와 <i>x</i>라는 두 독립변수에 대한 함수 <i>u(t, x)</i>의 변화를 나타냅니다.
            </li>
          </ul>
        </li>
      </ul>

      <h2>전통적인 편미분방정식 수치해석 기법</h2>
      <ol>        
        <li>
          <strong>편미분방정식의 활용:</strong>
          <ul>
            <li>유체(fluid), 탄성체, 변형체 등 다양한 물리 및 공학적 문제를 모델링하고 해석하는 데 사용됩니다.</li>
          </ul>
        </li>
        <li>
          <strong>전통적인 수치해석 방법:</strong>
          <ul>
            <li>
              <strong>유한차분법(FDM):</strong> PDE를 차분 방정식으로 변환하여 수치적으로 해석.
            </li>
            <li>
              <strong>유한요소법(FEM):</strong> 문제를 작은 요소(mesh)로 나누어 각 요소에 대해 수치해석 수행.
            </li>
          </ul>
        </li>
        <li>
          <strong>메시 기반 접근법:</strong>
          <ul>
            <li>계산 영역을 작은 메시(mesh)로 나누고 각 포인트에서 수치해를 계산.</li>
            <li>복잡한 형상의 문제를 해결할 때 사용.</li>
          </ul>
        </li>
        <li>
          <strong>한계:</strong>
          <ul>
            <li>계산량이 매우 많아지고, 복잡한 형상에서는 적용이 어려움.</li>
          </ul>
        </li>
      </ol>

      <h2>신경망을 이용한 편미분방정 수치적 해법의 가능성</h2>
      <ul>
        <li>
          <strong>신경망을 이용한 접근법:</strong>
          <ul>
            <li>신경망을 활용하여 편미분방정식을 수치적으로 푸는 방법이 수십 년 전부터 연구되고 개발되었습니다.</li>
          </ul>
        </li>
        <li>
          <strong>보편적 근사자 (Universal Approximator):</strong>
          <ul>           
            <li>신경망은 이론적으로 모든 연속함수를 임의의 정확도로 근사할 수 있다는 보편적 근사 정리에 기반하고 있습니다.</li>
          </ul>
        </li>
      </ul>
      
      <ul>
        <li>
          <strong>PINN의 정의:</strong>
          <ul>
            <li>Raissi가 개발한 물리 정보를 포함하는 신경망입니다.</li>
            <li>편미분방정식(PDE)의 물리 정보를 신경망 학습 과정에 통합.</li>
          </ul>
        </li>
        <li>
          <strong>PINN의 특징:</strong>
          <ul>
            <li>신경망 구조가 간단하고 직관적입니다.</li>
            <li><strong>Mesh-free 방법:</strong> 메쉬를 필요로 하지 않아 복잡한 형상에도 효과적으로 적용 가능.</li>
            <li>편미분방정식을 만족하도록 학습을 강제하여 물리적 일관성을 보장.</li>
          </ul>
        </li>
        <li>
          <strong>PINN의 장점:</strong>
          <ul>
            <li>신경망 학습에 필요한 데이터양을 줄여 학습 속도를 개선.</li>
            <li>물리 기반 모델링과 데이터 중심 접근법의 결합으로, 두 접근법의 장점을 모두 활용.</li>
          </ul>
        </li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/4.png" alt="4" class="deep-learning-image">
      </div>
      <ul>
        <li>
          <strong>장점:</strong>
          <ul>
            <li>충분한 데이터를 사용할 경우, 도메인 지식 없이도 적절한 수준의 예측 성능을 달성할 수 있습니다.</li>
            <li>데이터 중심 접근법으로 다양한 문제를 해결하는 데 유용합니다.</li>
          </ul>
        </li>
        <li>
          <strong>단점:</strong>
          <ul>
            <li>
              <strong>해석 가능성:</strong>
              <ul>
                <li>"어떻게 이런 결과가 나왔는지?"에 대한 설명이 부족합니다.</li>
              </ul>
            </li>
            <li>             
              <strong>일반화 가능성:</strong>
              <ul>
                <li>학습 데이터의 범위를 넘어선 영역 간 교차(interpolation) 또는 외삽(extrapolation)에서 성능이 떨어질 수 있습니다.</li>               
              </ul>
            </li>
          </ul>
        </li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/5.png" alt="5" class="deep-learning-image">
      </div>
      <ul>
        <li>
          <strong>장점:</strong>
          <ul>
            <li>충분한 데이터를 사용할 수 있는 경우, 도메인 지식 없이도 높은 예측 성능을 달성할 수 있음.</li>
          </ul>
        </li>
        <li>
          <strong>단점:</strong>
          <ul>
            <li>
              <strong>해석 가능성 부족:</strong>
              <ul>
                <li>"왜 이런 결과가 나왔는지"를 설명하기 어려움.</li>
              </ul>
            </li>
            <li>
              <strong>일반화 가능성 부족:</strong>
              <ul>
                <li>학습 데이터 외부 영역(외삽, extrapolation)에서의 성능이 저하.</li>
                <li>Interpolated 영역은 학습 데이터와 동일한 범위 내의 테스트이고, Extrapolated 영역은 학습 데이터의 범위를 벗어난 테스트를 나타냄.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <strong>시각적 해석:</strong>
          <ul>
            <li>
              <strong>왼쪽의 Interpolation 그림:</strong>
              <ul>
                <li>학습 데이터(회색)과 테스트 데이터(빨간색)가 동일한 범위에 포함되어 있어 일반적으로 성능이 우수.</li>
              </ul>
            </li>
            <li>
              <strong>오른쪽의 Extrapolation 그림:</strong>
              <ul>
                <li>테스트 데이터가 학습 데이터의 범위를 벗어난 경우, 일반화 성능이 저하되는 상황을 시각화.</li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/6.png" alt="6" class="deep-learning-image">
      </div>
      <ul>
        <li>
          <strong>장점:</strong>
          <ul>
            <li>충분한 데이터를 사용할 경우, 도메인 지식 없이도 높은 수준의 예측 성능을 달성 가능.</li>
          </ul>
        </li>
        <li>
          <strong>단점:</strong>
          <ul>
            <li>
              <strong>해석 가능성 부족:</strong>
              <ul>
                <li>결과를 설명하거나 해석하기 어려움.</li>
              </ul>
            </li>
            <li>
              <strong>일반화 가능성 부족:</strong>
              <ul>
                <li>학습 데이터 범위를 벗어난 외삽(<code>extrapolation</code>) 영역에서의 성능 저하.</li>
                <li>오른쪽 그래프에서 학습 데이터 범위(파란색 선 내부)에서는 정확한 예측이 가능하나, 범위를 넘어가면 성능이 급격히 악화됨(빨간색 선).</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <strong>신경망 예제:</strong>
          <ul>
            <li>간단한 신경망으로 사인 함수 <code>sin(x)</code>를 예측.</li>
            <li>학습 데이터 범위 내에서는 <code>sin(x)</code>를 잘 예측하지만, 범위를 벗어나면 잘못된 값을 출력.</li>
          </ul>
        </li>
      </ul>

      <h2>기존 신경망의 단점을 보완해줄 새로운 신경망</h2>
      <h3>→ Physics Informed Neural Network (PINN)</h3>
      <ul>
        <li><strong>data + physics to build a model</strong></li>
        <li>기존 신경망의 단점 보완</li>
        <li>축적된 과학 이론의 사전 지식으로 데이터 과학 방법을 최대한 활용 → 예측 성능 향상</li>
        <li>데이터 불균형 및 데이터 부족 문제를 해결하기 위한 도메인 지식 통합</li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/7.png" alt="7" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>Data-driven AI:</strong>
          <ul>
            <li>데이터 중심의 인공지능 모델.</li>
            <li>입력과 출력 간의 관계를 학습 데이터로부터 학습.</li>
            <li>물리적 제약이나 이론 없이 데이터를 기반으로 예측 수행.</li>
          </ul>
        </li>
        <li>
          <strong>Physics-informed AI (PINN):</strong>
          <ul>
            <li>데이터와 물리적 제약(예: 편미분방정식)을 통합한 인공지능 모델.</li>
            <li>입력과 출력 사이의 관계를 학습할 뿐만 아니라, 물리 방정식을 제약 조건으로 사용하여 학습.</li>
            <li>예시로는 Navier-Stokes 방정식(유체역학에서 사용되는 방정식)이 포함됨.</li>
          </ul>
        </li>
      </ol>
      <ul>
        <li>
          <strong>Data-driven AI:</strong>는 데이터가 충분히 많고 범위 내의 문제에서는 효과적이지만, 물리적 일반성을 보장하기 어렵습니다.
        </li>
        <li>
          반면, <strong>Physics-informed AI:</strong>는 물리 법칙을 포함하여 데이터 부족 문제를 보완하고, 학습된 모델이 물리적으로 타당한 예측을 할 수 있도록 만듭니다.
        </li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/8.png" alt="8" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>PINN의 역할:</strong>
          <ul>
            <li>PINN은 물리 문제를 해결하기 위한 물리 해석 도구로 사용됩니다.</li>
            <li>물리적 손실(Physics loss)을 통해 데이터가 없어도 작동할 수 있습니다.</li>
            <li>물리학과 데이터를 모두 사용해 손실 함수를 계산하여 예측을 수행합니다.</li>
          </ul>
        </li>
        <li>
          <strong>구조 설명:</strong>
          <ul>
            <li>
              <strong>Fully-connected Network:</strong>
              <ul>
                <li>입력값 (<code>x, y</code>)을 기반으로 신경망에서 예측값 (<code>û, ṽ, ṗ</code>)을 생성.</li>
              </ul>
            </li>
            <li>
              <strong>Physics-Informed Network:</strong>
              <ul>
                <li>예측값에 대해 물리 방정식(편미분방정식)을 적용해 물리적 일관성을 평가.</li>
                <li>물리 손실은 다음의 요소를 포함:
                  <ul>
                    <li>
                      <strong>Governing equation (지배 방정식):</strong> 물리적 현상을 기술하는 핵심 방정식.
                    </li>
                    <li>
                      <strong>Boundary conditions (경계 조건):</strong> 문제의 경계에서 물리적 제약.
                    </li>
                    <li>
                      <strong>Initial conditions (초기 조건):</strong> 초기 상태에서의 제약.
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <strong>손실 함수:</strong>
          <ul>
            <li>총 손실 (<code>L<sub>total</sub></code>) = 물리 손실 (<code>L<sub>physics</sub></code>) + 데이터 손실 (<code>L<sub>data</sub></code>).</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/9.png" alt="9" class="deep-learning-image">
      </div>      
      <ol>
        <li>
          <strong>보편적 함수 근사자:</strong>
          <ul>
            <li>신경망(NN)은 보편적 함수 근사자(universal function approximator)로, 어떤 함수도 학습할 수 있는 능력을 가짐.</li>
          </ul>
        </li>
        <li>
          <strong>문제 설정:</strong>
          <ul>
            <li>주어진 물리적 방정식(예: ODE 또는 PDE) 및 초기/경계 조건 데이터.</li>
            <li>예시 방정식<br>
              <img src="Deep learning10 images/10.png" alt="10">
            </li>
          </ul>
        </li>
        <li>
          <strong>정규화 제약 추가:</strong>
          <ul>
            <li>물리적 제약 조건을 추가해 신경망을 정규화.</li>
            <li>데이터를 보완하여 드문 데이터(sparse data)에서도 신뢰성 있는 결과 제공.</li>
          </ul>
        </li>
        <li>
          <strong>손실 함수:</strong>
          <ul>
            <li>총 손실 (<code>L</code>)은 데이터 손실 (<code>L<sub>data</sub></code>)와 PDE 손실 (<code>L<sub>PDE</sub></code>)의 가중합<br>
              <img src="Deep learning10 images/11.png" alt="11">
            </li>
            <li>데이터 손실 (<code>L<sub>data</sub></code>)<br>
              <img src="Deep learning10 images/12.png" alt="12">
            </li>
            <li>PDE 손실 (<code>L<sub>PDE</sub></code>)<br>
              <img src="Deep learning10 images/13.png" alt="13">
            </li>
          </ul>
        </li>
        <li>
          <strong>구조적 시각화:</strong>
          <ul>
            <li>입력값 (<code>x, t</code>)를 통해 신경망이 예측값 (<code>û</code>)을 생성.</li>
            <li>PDE와 데이터 손실을 함께 학습하여 물리적 일관성을 유지.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/14.png" alt="14" class="deep-learning-image">
      </div>
      <ul>
        <li>
          <strong>손실 함수:</strong>
          <ul>
            <li><strong>Strong Form</strong> 기반 손실 함수 사용.</li>
            <li>손실 함수 최적화를 위해 Adam 및 quasi-Newton L-BFGS와 같은 최적화 알고리즘을 자주 활용.</li>
            <li>물리적 방정식(PDE)을 통해 계산된 잔차를 포함하여 손실을 계산.</li>
          </ul>
        </li>
        <li>
          <strong>구조적 작업 원리:</strong>
          <ul>
            <li>입력 값 (<code>x, t</code>)이 신경망에 전달되어 출력 (<code>u<sub>θ</sub></code>)를 생성.</li>
            <li>PDE의 미분 연산 (<code>∂/∂t, ∂/∂x, ∂²/∂x²</code>)을 적용하여 PDE 잔차를 계산.</li>
            <li>잔차와 데이터 기반 손실을 결합한 총 손실이 기준(<code>L</code>)이 하강하면 학습 완료.</li>
          </ul>
        </li>
        <li>
          <strong>Meshfree 접근 방식:</strong>
          <ul>
            <li><strong>Deep Collocation Method</strong> 사용:</li>
            <ul>
              <li>Mesh를 생성하지 않고, 몬테카를로 샘플링(Monte Carlo Sampling)을 통해 데이터 포인트를 무작위로 샘플링.</li>
              <li>오른쪽 그림은 시간 및 위치에서 무작위로 샘플링된 포인트를 보여줌 (빨간 원: 샘플링된 포인트, 파란 X: 경계 조건).</li>
            </ul>
          </ul>
        </li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/15.png" alt="15" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>위의 모델:</strong>
          <ul>
            <li>고정된 보(beam) 구조에 대한 물리적 시스템을 나타냅니다.</li>
            <li><strong>방정식</strong></li>
            <img src="Deep learning10 images/16.png" alt="16" class="deep-learning-image">
            <ul>
              <li><strong>ω</strong>: 변위</li>
              <li><strong>EI</strong>: 곱합 강성</li>
              <li><strong>μ</strong>: 질량</li>
              <li><strong>q</strong>: 외부 하중</li>
            </ul>
            <li>센서 배열(sensor array)이 보 위에 배치되어 데이터를 수집.</li>
          </ul>
        </li>
        <li>
          <strong>아래의 그래프:</strong>
          <ul>
            <li>3D 그래프로 <strong>오류(Error)</strong>를 센서 개수(<strong># of sensors</strong>) 및 신호 대 잡음비(SNR, dB)에 따라 비교.</li>
            <li><strong>두 모델 비교:</strong></li>
            <ul>
              <li><strong>파란색 점 (Physics-Informed):</strong> PINN 모델의 오류.</li>
              <li><strong>주황색 삼각형 (Data-Driven):</strong> 데이터 기반 신경망의 오류.</li>
            </ul>
          </ul>
        </li>
      </ol>
      <h3>분석</h3>
      <ul>
        <li>센서의 개수가 적거나 SNR이 낮은 경우, PINN의 오류가 데이터 기반 모델보다 훨씬 낮음.</li>
        <li>데이터 기반 모델은 센서와 SNR의 의존도가 크며, 데이터 부족 또는 품질 저하 시 성능이 크게 저하.</li>
        <li>PINN은 물리적 제약을 활용하여 데이터 부족 환경에서도 높은 성능을 유지.</li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/17.png" alt="17">
      </div>
      <ol>
        <li>
          <strong>위 그래프 (Data):</strong>
          <ul>
            <li>데이터만을 사용하여 계산된 속도 <strong>u</strong> 분포를 보여줍니다.</li>
            <li>데이터 포인트는 제한적이며, 특정 위치에만 집중되어 있습니다.</li>
            <li>이는 물리적 방정식을 고려하지 않은 순수 데이터 기반 모델의 결과를 시각화한 것입니다.</li>
          </ul>
        </li>
        <li>
          <strong>아래 그래프 (Data + Collocation):</strong>
          <ul>
            <li>데이터와 함께 <strong>Collocation Points</strong>를 추가로 사용하여 계산된 속도 <strong>u</strong> 분포를 보여줍니다.</li>
            <li><strong>Collocation Points:</strong> 균일하게 분포된 추가 샘플링 포인트로, 물리 방정식(PDE)을 만족하도록 활용됩니다.</li>
            <li>물리적 제약 조건이 추가되어 전체적으로 더 세밀하고 일관성 있는 결과를 제공합니다.</li>
          </ul>
        </li>
      </ol>
      
      <h3>주요 차이점:</h3>
      <ul>
        <li>
          <strong>데이터만 사용한 경우:</strong>
          <ul>
            <li>데이터가 제공된 영역에서만 정확도가 높으며, 다른 영역에서는 정보가 부족.</li>
            <li>제한된 데이터로 인해 물리적 일관성이 결여될 가능성이 큼.</li>
          </ul>
        </li>
        <li>
          <strong>데이터 + Collocation 사용한 경우:</strong>
          <ul>
            <li><strong>Collocation Points</strong>가 물리 방정식을 기반으로 추가되며, 데이터가 부족한 영역에서도 물리적 일관성을 유지.</li>
            <li>전체적인 분포가 더 세밀하고 정밀함.</li>
          </ul>
        </li>
      </ul>

      <h2>기존 신경망 예측(데이터50,000개)</h2>
      <div class="image-section.left">
        <img src="Deep learning10 images/18.png" alt="18" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>첫 번째 그래프 (Velocity u):</strong>
          <ul>
            <li>x축(길이 방향)에서 속도 <code>u</code>의 분포를 나타냅니다.</li>
            <li>중심부에서는 높은 속도(빨간색), 경계에서는 낮은 속도(파란색)를 보여주는 층류 패턴.</li>
          </ul>
        </li>
        <li>
          <strong>두 번째 그래프 (Velocity v):</strong>
          <ul>
            <li>y축(거리 방향)에서의 속도 <code>v</code> 분포.</li>
            <li>경계 근처에서 뚜렷한 속도 변화가 발생하며, 이는 경계 효과를 반영.</li>
          </ul>
        </li>
        <li>
          <strong>세 번째 그래프 (Pressure P):</strong>
          <ul>
            <li>압력 분포를 나타내며, x축 방향으로 압력이 점진적으로 감소.</li>
            <li>이는 정상 상태 흐름에서 일반적으로 관찰되는 압력 강하를 반영.</li>
          </ul>
        </li>
      </ol>
      
      <h3>해석</h3>
      <ul>
        <li>모델은 데이터 50,000개를 사용하여 안정적인 결과를 산출하였으며, 물리적 패턴(속도 및 압력 분포)을 잘 반영하고 있습니다.</li>
        <li>하지만, <strong>데이터만 사용한 기존 신경망</strong>은 다음과 같은 한계를 가질 수 있습니다:
          <ul>
            <li>데이터가 충분히 많을 경우 높은 정확도를 달성할 수 있으나, 데이터가 부족하거나 품질이 낮은 경우 성능 저하 가능.</li>
            <li>물리적 제약 조건이 포함되지 않아, 데이터 범위를 벗어난 일상 상황에서 일반성이 떨어질 수 있음.</li>
          </ul>
        </li>
      </ul>
      
      <h2>기존 신경망 예측(데이터3,692개)</h2>
      <div class="image-section.left">
        <img src="Deep learning10 images/19.png" alt="19" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>첫 번째 그래프 (Velocity u):</strong>
          <ul>
            <li>흐름 방향(x축) 속도 분포.</li>
            <li>중앙부에서는 높은 속도(빨간색), 경계에서는 낮은 속도(파란색)를 보이나, 데이터가 부족해 일부 구간에서 경계 흐름이 부정확하게 나타날 가능성이 있습니다.</li>
          </ul>
        </li>
        <li>
          <strong>두 번째 그래프 (Velocity v):</strong>
          <ul>
            <li>수직 방향(y축) 속도 분포.</li>
            <li>경계 근처에서 변화가 나타나지만, 데이터 부족으로 인해 흐름 패턴이 매끄럽지 않을 가능성이 있음.</li>
          </ul>
        </li>
        <li>
          <strong>세 번째 그래프 (Pressure P):</strong>
          <ul>
            <li>압력 분포.</li>
            <li>압력 강하가 일정하게 나타나지 않을 가능성이 있으며, 데이터 부족으로 인해 세부적인 압력 변화가 정확히 반영되지 않을 수 있음.</li>
          </ul>
        </li>
      </ol>
      
      <h3>해석</h3>
      <ul>
        <li>데이터가 3,692개로 제한된 경우, 기존 신경망은 성능이 저하될 수 있습니다.</li>
        <li>데이터 의존성이 높은 기존 신경망은 부족한 데이터에서 일반화와 정확도가 낮아질 가능성이 큽니다.</li>
        <li>물리적 제약이 없는 상황에서 데이터 외삽 영역에서 성능이 악화될 가능성도 존재.</li>
      </ul>

      <h2>기존 신경망 예측(데이터3,692개)</h2>
      <div class="image-section.left">
        <img src="Deep learning10 images/20.png" alt="20" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>첫 번째 그래프 (Velocity u):</strong>        
          <ul>
            <li>x-축 방향 속도 분포.</li>
            <li>데이터가 매우 부족한 경우, 결과에 불연속적인 패턴(빈 공간과 분리된 영역)이 나타남.</li>
            <li>이는 모델이 데이터 부족으로 인해 물리적 연속성을 보장하지 못하는 것을 보여줌.</li>
          </ul>
        </li>
        <li>
          <strong>두 번째 그래프 (Velocity v):</strong>
          <ul>
            <li>y-축 방향 속도 분포.</li>
            <li>경계 및 내부 흐름에서 불규칙한 패턴이 발생하며, 데이터 부족으로 인해 부정확한 예측 결과를 확인할 수 있음.</li>
          </ul>
        </li>
        <li>
          <strong>세 번째 그래프 (Pressure P):</strong>
          <ul>
            <li>압력 분포.</li>
            <li>전체적으로 매끄럽지 못한 패턴을 보이며, 압력 강하가 불규칙적이고 물리적 일관성이 부족.</li>
          </ul>
        </li>
      </ol>
      
      <h3>해석</h3>
      <ul>
        <li>데이터가 672개로 제한된 경우, 기존 신경망 모델의 성능이 크게 저하됩니다.</li>
        <li>속도 u 분포에서 분리된 영역이 발생하여 물리적 연속성이 훼손.</li>
        <li>압력 분포의 심화할수록 모델의 예측이 실제 물리적 현상을 반영하지 못함.</li>
        <li>압력 분포에서 동일한 문제가 나타나며, 전반적으로 모델의 신뢰성이 낮아짐.</li>
      </ul>

      <p>기존 신경망은 데이터 의존도가 매우 높아, 데이터가 부족한 상황에서는 물리적 일관성과 정확도를 유지하기 어렵습니다. 
        **PINN(Physics-Informed Neural Network)**은 물리 방정식을 통합하여 데이터가 적더라도 더 신뢰성 있고 일관된 결과를 제공할 수 있는 해결책이 될 수 있습니다.</p><br>

      <P>예시를 통해 연습을 해보겠습니다.</P>
      <h3>예제 1</h3>
      <p>다음 데이터는 자유 낙하하는 공의 지면으로부터의 위치 데이터를 나타낸 것입니다.</p>
      <ul>
        <li>0~8초까지 0.2초 간격으로 위치 데이터가 있다고 가정하고, 이 데이터를 학습하여 8초 이후의 위치를 예측하는 신경망을 만들어 보겠습니다.</li>
      </ul>
      <p><strong>기존 신경망과 상미분방정식의 정보가 들어간 PINN을 비교해보도록 하겠습니다.</strong></p>
      <h2>먼저 상미분방정식의 정보가 없이 기존 신경망 학습을 해보겠습니다.</h2>

      <div class="image-section.left">
        <img src="Deep learning10 images/21.png" alt="21" class="deep-learning-image">
      </div>
      <li>이 코드는 딥러닝 실험 환경을 설정하는 초기 작업으로, GPU 활용 여부를 확인하고 Google Drive와 연동해 데이터 파일을 쉽게 관리할 수 있도록 준비하는 단계입니다. Colab에서 신경망 학습이나 데이터 처리를 위한 기본 설정입니다.</li>

      <div class="image-section.left">
        <img src="Deep learning10 images/22.png" alt="22" class="deep-learning-image">
      </div>
      <ul>
        <li><strong>데이터 구조:</strong>
          <ul>
            <li>공의 자유 낙하를 시뮬레이션한 시간(<code>time</code>)과 높이(<code>Height</code>)의 데이터로 구성되어 있음.</li>
            <li>총 71개의 데이터로, 시간은 0~14초 범위, 초기 높이는 1,000m에서 시작하여 점진적으로 감소.</li>
          </ul>
        </li>
        <li><strong>활용 목적:</strong>
          <ul>
            <li>학습 데이터(0~8초)로 모델을 학습한 뒤, 테스트 데이터(8초 이후)에서 예측 성능 평가.</li>
            <li>기존 신경망과 PINN의 성능 비교를 통해 PINN의 물리적 일관성과 외삽 능력을 확인.</li>
          </ul>
        </li>
        <li><strong>다음 단계:</strong>
          <ol>
            <li>시간-높이 데이터를 시각화.</li>
            <li>학습 및 테스트 데이터로 분리.</li>
            <li>기존 신경망과 PINN을 활용하여 모델 학습 및 예측 성능 비교.</li>
          </ol>
        </li>
      </ul>
      <p>이러한 내용을 기반으로 신경망 모델 학습을 진행할 준비가 완료되었습니다.</p>

      <div class="image-section.left">
        <img src="Deep learning10 images/23.png" alt="23" class="deep-learning-image">
      </div>
      <ol>
        <li><strong>데이터 분리:</strong>
          <ul>
            <li><code>train_time = 40</code>: 학습 데이터는 40개의 시간 값(0초부터 8초까지)을 사용.</li>
            <li>학습 및 테스트 데이터 분리:
              <ul>
                <li><code>x_train, y_train</code>: 학습용 시간 및 높이 데이터.</li>
                <li><code>x_test, y_test</code>: 테스트용 시간 및 높이 데이터.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li><strong>텐서(Tensor) 변환:</strong>              
          <ul>
            <li>학습 및 테스트 데이터를 PyTorch 텐서로 변환.</li>
            <li><code>.reshape(-1, 1)</code>: 데이터를 2차원 형태로 변환 (PyTorch에서 신경망 입력 형식).</li>
            <li><code>.to(device)</code>: 데이터를 GPU 또는 CPU로 이동.</li>
          </ul>
        </li>
        <li><strong>입출력 차원 설정:</strong>
          <pre>
n_input = 1    # 입력 뉴런 수 (시간 데이터)
n_output = 1   # 출력 뉴런 수 (높이 데이터)
n_hidden = 50  # 은닉층 뉴런 수</pre>
          <ul>
            <li>입력과 출력은 각기 1차원 데이터를 처리하며, 은닉층은 50개의 뉴런으로 구성.</li>
          </ul>
        </li>
        <li><strong>출력 확인:</strong>
          <ul>           
            <li><code>x_train.shape</code>: 학습 데이터 크기를 출력.</li>
            <li><strong>결과:</strong> <code>(41, 1)</code> → 총 41개의 학습 데이터 포인트, 각 포인트는 1차원.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/24.png" alt="24" class="deep-learning-image">
      </div>
      <ol>
        <li><strong>신경망 클래스 정의:</strong>
          <ul>
            <li><code>class Net(nn.Module)</code>: PyTorch에서 <code>nn.Module</code>을 상속받아 신경망 구조 정의.</li>
            <li><strong>구성:</strong>
              <ul>
                <li>입력층: <code>self.l1</code> → 입력 뉴런 수에서 은닉층 뉴런 수로 연결.</li>
                <li>은닉층: <code>self.l2, self.l3</code> → 은닉층에서 은닉층으로 연결.</li>
                <li>출력층: <code>self.l4</code> → 은닉층 뉴런 수에서 출력 뉴런 수로 연결.</li>
              </ul>
            </li>
            <li><strong>활성화 함수:</strong> ReLU(Rectified Linear Unit) 활성화 함수: <code>self.relu = nn.ReLU()</code>를 사용.</li>
          </ul>
        </li>
        <li><strong>순전파(forward):</strong>
          <ul>
            <li>입력 데이터를 활성화 함수를 통해 연속적으로 처리:</li>
            <li>입력 ➝ 은닉층 1 (ReLU 적용) ➝ 은닉층 2 (ReLU 적용) ➝ 은닉층 3 (ReLU 적용) ➝ 출력층.</li>
          </ul>
        </li>
        <li><strong>랜덤 시드 설정:</strong>
          <pre>
torch.cuda.manual_seed(123)</pre>
          <ul>
            <li>동일한 결과를 재현하기 위해 랜덤 시드를 고정.</li>
          </ul>
        </li>
        <li><strong>모델 초기화 및 설정:</strong>
          <pre>
model = Net()
model = model.to(device)</pre>
          <ul>
            <li><code>Net</code> 클래스의 인스턴스를 생성하여 모델로 설정.</li>
            <li><code>device</code> (GPU 또는 CPU)에 모델을 할당.</li>
          </ul>
        </li>
        <li><strong>학습률 및 최적화 기법:</strong>
          <pre>
lr = 0.001
optimizer = torch.optim.Adam(model.parameters(), lr=lr)</pre>
          <ul>
            <li><strong>학습률(Learning Rate):</strong> 0.001.</li>
            <li>Adam Optimizer를 사용하여 신경망 파라미터 최적화.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/25.png" alt="25" class="deep-learning-image">
      </div>
      <ul>
        <li>이 신경망은 <strong>4개의 선형 계층</strong>과 ReLU 활성화 함수로 구성된 다층 퍼셉트론(MLP) 구조입니다.</li>
        <li>입력값(시간)을 받아 높이값을 출력하는 단순 회귀 문제를 해결하도록 설계.</li>
        <li>은닉층 뉴런 수가 충분히 크기 때문에 데이터의 복잡한 패턴을 학습할 수 있는 잠재력이 있습니다.</li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning10 images/26.png" alt="26" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>학습 프로세스:</strong>
          <ul>
            <li><strong>목표:</strong> 입력 데이터(<code>x_train</code>)와 실제 출력 데이터(<code>y_train</code>)를 기반으로 신경망을 학습시켜 예측 오차(손실)를 줄이는 것.</li>
            <li>
              <strong>학습 루프는 10,000번(epoch) 반복되며, 다음 단계로 구성:</strong>
              <ol>
                <li>순전파: 모델을 사용해 예측값 계산 (<code>preds_train</code>).</li>
                <li>손실 계산: 예측값과 실제값 간의 평균 제곱 오차(MSE) 계산 (<code>loss_train</code>, <code>loss_test</code>).</li>
                <li>역전파: 손실 함수에 대해 모델의 모든 매개변수의 기울기 계산.</li>
                <li>최적화: 기울기를 사용하여 모델 매개변수를 업데이트.</li>
                <li>손실 기록: 각 epoch의 학습 및 테스트 손실 저장.</li>
              </ol>
            </li>
          </ul>
        </li>
        <li>
          <strong>손실 기록 및 출력:</strong>
          <ul>
            <li>매 1,000번째 epoch마다 학습(<code>loss_train</code>) 및 테스트(<code>loss_test</code>) 손실 출력.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/27.png" alt="27" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>그래프 설명:</strong>
          <ul>
            <li><strong>파란 선 (<code>train_error</code>):</strong> 학습 데이터의 손실 변화.</li>
            <li><strong>빨간 선 (<code>test_error</code>):</strong> 테스트 데이터의 손실 변화.</li>
          </ul>
        </li>
        <li>
          <strong>초기 손실:</strong>
          <ul>
            <li>초기에는 학습 데이터와 테스트 데이터 모두 손실이 매우 높음.</li>
            <li>학습이 진행되면서 손실이 급격히 감소.</li>
          </ul>
        </li>
        <li>
          <strong>학습 손실 (<code>Train Error</code>):</strong>
          <ul>
            <li>1,000번의 epoch 이후 안정적으로 낮아짐.</li>
            <li>최종적으로 매우 낮은 손실 값을 유지, 학습 데이터에 대한 신경망의 성능이 우수함을 보여줌.</li>
          </ul>
        </li>
        <li>
          <strong>테스트 손실 (<code>Test Error</code>):</strong>
          <ul>
            <li>초기에는 급격히 감소하지만, 학습 손실에 비해 훨씬 높은 값에서 점차 안정화.</li>
            <li>외삽 영역(8초 이후)의 데이터를 잘 예측하지 못함을 나타냄.</li>
          </ul>
        </li>
        <li>
          <strong>손실 간 격차:</strong>
          <ul>
            <li>학습 손실과 테스트 손실 간의 큰 차이는 기존 신경망의 외삽 성능 부족 때문.</li>
            <li>테스트 데이터가 학습 데이터 범위 밖에 위치하기 때문에 일반화 능력이 제한됨.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/28.png" alt="28" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>그래프 설명:</strong>
          <ul>
            <li><strong>점선형 점선 (<code>Real_data</code>):</strong> 실제 데이터의 높이(<code>Height</code>)를 나타냄. 시간에 따라 자유 낙하하는 공의 위치 데이터.</li>
            <li><strong>파란 선 (<code>Predicted_train</code>):</strong> 학습 데이터 구간(0초 ~ 8초)에 대한 모델 예측 값. 실제 데이터와 거의 일치.</li>
            <li><strong>빨간 선 (<code>Predicted_test</code>):</strong> 테스트 데이터 구간(8초 이후)에 대한 모델 예측 값. 실제 데이터와 큰 오차 발생.</li>
          </ul>
        </li>
        <li>
          <strong>학습 데이터 구간 (0초 ~ 8초):</strong>
          <ul>
            <li>모델이 학습 데이터를 정확히 예측하고 있음.</li>
            <li>파란 선과 점선형 점선이 거의 겹침.</li>
          </ul>
        </li>
        <li>
          <strong>테스트 데이터 구간 (8초 이후):</strong>
          <ul>
            <li>빨간 선이 점선형 점선과 크게 벗어남.</li>
            <li>기존 신경망은 학습 데이터의 범위를 벗어난 데이터(<code>외삽</code>)에 대해 예측 정확도가 떨어짐.</li>
          </ul>
        </li>
        <li>
          <h2>결론:</h2>
          <ul>
            <li><strong>학습 데이터:</strong> 모델이 학습 데이터 구간에서는 높은 예측 정확도를 보임.</li>
            <li><strong>테스트 데이터:</strong> 외삽 데이터(8초 이후)에서는 예측 오차가 커지는 한계를 가짐. 이는 기존 신경망이 물리적 제약 없이 데이터 의존적으로 학습했기 때문.</li>
            <li><strong>다음 단계:</strong> PINN(Physics-Informed Neural Network)을 도입하여 물리적 제약(운동 방정식)을 학습 과정에 추가. 외삽 영역에서의 예측 성능을 개선할 필요.</li>
          </ul>
        </li>
      </ol>
      
      <h2>이번에는 상미분방정식의 정보가 들어간 PINN을 구현해보겠습니다.</h2>
      <div class="image-section.left">
        <img src="Deep learning10 images/29.png" alt="29" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>중력가속도:</strong>
          <ul>
            <li>자유 낙하 시 중력가속도는 <code>9.8m/s²</code>로 일정합니다.</li>
            <li>시간에 따른 속도 변화는 중력가속도와 시간의 곱으로 표현됩니다. 즉, <code>-9.8t</code> (속도는 음수).</li>
          </ul>
        </li>
        <li>
          <strong>물리법칙 적용:</strong>
          <ul>
            <li>위치를 시간으로 미분하면 속도가 되며, 이는 다음 미분방정식을 만족합니다:</li>
            <img src="Deep learning10 images/30.png" alt="30">
            <li>이는 자유 낙하하는 물체의 운동 방정식입니다.</li>
          </ul>
        </li>
        <li>
          <strong>초기 조건:</strong>
          <ul>
            <li>데이터에서 초기 위치는 <code>s(0) = 1000m</code>로 설정되어 있습니다.</li>
            <li>이를 통해 모델의 경계 조건(<code>boundary condition</code>)을 정의할 수 있습니다.</li>
          </ul>
        </li>
        <li>
          <strong>코드 정의:</strong>
          <pre>
def ODE(t):
return -9.8 * t</pre>
          <ul>
            <li>위 미분방정식은 코드로 구현 시 위와 같이 정의됩니다.</li>
          </ul>
        </li>
        <li>
          <strong>PINN 구조:</strong>
          <ul>
            <li>신경망 학습에 물리적 손실(<code>Physics loss</code>)과 데이터 손실(<code>Data loss</code>)을 결합하여 최적화.</li>
            <li>물리적 법칙(<code>Governing equation</code>)과 초기 조건(<code>Initial condition</code>)을 만족하도록 설계.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/31.png" alt="31" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>Boundary Condition 부재:</strong>
          <ul>
            <li>이 문제에서 경계 조건(<code>Boundary condition</code>)은 특별히 적용되지 않습니다.</li>
            <li>하지만 초기 조건(<code>Initial condition</code>)은 주어져 있으며, 초기 시간 <code>t = 0</code>에서 위치는 <code>s(0) = 1000m</code>로 설정됩니다.</li>
          </ul>
        </li>
        <li>
          <strong>초기 조건 설정:</strong>
          <pre>
x_H0 = torch.Tensor([0])   # 초기 시간 t = 0
y_H0 = torch.Tensor([1000]) # 초기 위치 s(0) = 1000</pre>
        </li>
        <li>
          <strong>Physics-Informed Loss:</strong>
          <ul>
            <li>물리적 법칙을 따르는 네트워크 학습에서 초기 조건은 <strong>초기 손실(Initial condition loss)</strong>로 반영됩니다.</li>
            <li><code>L_IC</code>: 초기 조건에서의 오차를 최소화하도록 학습.</li>
          </ul>
        </li>
      </ol>

      <h2>그렇다면 미분방정식의 손실값을 어떻게 정의할까?</h2>
      <h3>Deep collocation method (심층 콜로케이션 방법)</h3>
      <ul>
        <li>Monte Carlo sampling method 사용</li>
      </ul>
      <h4>Monte Carlo sampling method:</h4>
      <p>반복된 무작위 추출(repeated random sampling)을 이용하여 함수의 값을 수치적으로 근사하는 알고리즘을 부르는 용어.</p>
      <ol>
        <li>가지고 있는 데이터에 상관없이 정의역(시간)에 범위 또는 구하고자 하는 시간의 범위를 정한다.</li>
        <li>반복된 무작위 추출 함수로 <code>uniform random distribution</code> 함수를 사용하여 정해진 범위에 N개의 무작위 샘플링을 한다.</li>
        <li>무작위 샘플링한 시간의 미분방정식 값과 신경망에서 구한 미분값과의 평균제곱오차를 계산한다.</li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/32.png" alt="32" class="deep-learning-image">
      </div>
      <li>이 코드는 주어진 시간 범위 내에서 콜로케이션 포인트를 생성하여, 미분방정식의 손실 계산에 사용될 데이터를 준비하는 단계입니다.</li>
      
      <div class="image-section.left">
        <img src="Deep learning10 images/33.png" alt="33" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>클래스 정의:</strong>
          <ul>
            <li><code>PINN_test(nn.Module)</code>은 PyTorch의 <code>nn.Module</code>을 상속받아 정의된 신경망 클래스입니다.</li>
          </ul>
        </li>
        <li>
          <strong>__init__ 메서드:</strong>
          <ul>
            <li>활성화 함수 <code>tanh</code>를 정의: <code>self.tanh = nn.Tanh()</code>.</li>
            <li>네 개의 선형 계층(linear layers) 정의:
              <ul>
                <li><code>self.l1</code>: 입력 1차원 → 출력 50차원.</li>
                <li><code>self.l2</code>: 입력 50차원 → 출력 50차원.</li>
                <li><code>self.l3</code>: 입력 50차원 → 출력 50차원.</li>
                <li><code>self.l4</code>: 입력 50차원 → 출력 1차원.</li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <strong>forward 메서드:</strong>
          <ul>
            <li>입력 데이터 <code>x</code>가 순차적으로 각 계층(<code>l1</code> ~ <code>l4</code>)을 통과.</li>
            <li>각 계층 사이에서 <code>tanh</code> 활성화 함수 적용.</li>
            <li>최종 결과 반환.</li>
          </ul>
        </li>
      </ol>
      <p>이 신경망은 <strong>Physics-Informed Neural Network (PINN)</strong>의 구조로, 물리 법칙 기반 손실 함수와 데이터를 결합하여 학습을 수행하는 데 사용됩니다. <code>tanh</code> 활성화 함수를 사용하여 비선형성을 반영합니다.</p>

      <div class="image-section.left">
        <img src="Deep learning10 images/34.png" alt="34" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>랜덤 시드 설정:</strong>
          <ul>
            <li><code>torch.cuda.manual_seed(123)</code>: 재현 가능한 결과를 위해 CUDA 환경에서 랜덤 시드를 123으로 고정.</li>
          </ul>
        </li>
        <li>
          <strong>모델 생성:</strong>
          <ul>
            <li><code>model_P = PINN_test()</code>: 이전에 정의된 <code>PINN_test</code> 클래스를 기반으로 모델을 생성.</li>
            <li><code>model_P = model_P.to(device)</code>: 생성된 모델을 GPU 또는 CPU 장치(<code>device</code>)로 이동.</li>
          </ul>
        </li>
        <li>
          <strong>최적화기 정의:</strong>
          <ul>
            <li><code>optimizer_P = torch.optim.Adam(model_P.parameters(), lr=lr)</code>:</li>
            <ul>
              <li>Adam 최적화기를 사용하여 모델의 파라미터를 업데이트.</li>
              <li>학습률(<code>lr</code>)은 외부에서 정의된 값 사용.</li>
            </ul>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/35.png" alt="35" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>손실 함수 구성:</strong>
          <ul>
            <li><code>loss_BC</code>: 초기 조건 손실(초기 위치와 모델의 예측 값 간의 차이).</li>
            <li><code>loss_ODE</code>: 미분 방정식 손실(모델의 예측 값이 물리 법칙을 얼마나 만족하는지).</li>
            <li><code>loss_Data</code>: 데이터 손실(모델이 학습 데이터와 얼마나 잘 맞는지).</li>
          </ul>
        </li>
        <li>
          <strong>손실 함수 합산:</strong>
          <ul>
            <li><code>loss = loss_BC + loss_ODE + loss_Data</code>: 총 손실은 세 가지 손실 함수의 합.</li>
          </ul>
        </li>
        <li>
          <strong>역전파 및 모델 업데이트:</strong>
          <ul>
            <li><code>loss.backward()</code>: 손실을 기준으로 모델 파라미터의 그래디언트 계산.</li>
            <li><code>optimizer_P.step()</code>: Adam 최적화기를 사용하여 모델 파라미터 업데이트.</li>
          </ul>
        </li>
        <li>
          <strong>훈련 진행 및 기록:</strong>
          <ul>
            <li><code>loss_train_P.append(loss.item())</code>: 각 스텝의 훈련 손실 기록.</li>
            <li><code>loss_test_P.append(loss_test.item())</code>: 각 스텝의 테스트 손실 기록.</li>
          </ul>
        </li>
        <li>
          <strong>출력:</strong>
          <ul>
            <li>10 스텝마다 <code>loss</code> 출력으로 학습 과정 확인.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/36.png" alt="36" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>그래프 내용:</strong>
          <ul>
            <li><strong>파란색<code>train_error</code></strong>: 훈련 손실로, 학습 데이터에 대한 모델의 성능을 나타냅니다.</li>
            <li><strong>빨간색<code>test_error</code></strong>: 테스트 손실로, 검증 데이터에 대한 모델의 성능을 나타냅니다.</li>
          </ul>
        </li>
        <li>
          <strong>결과 해석:</strong>
          <ul>
            <li>초기 학습 단계에서 훈련 손실과 테스트 손실 모두 감소하며 모델이 데이터에 적합해지고 있음을 보여줍니다.</li>
            <li>약 20,000 스텝 이후 손실 값이 안정화되며, 모델이 수렴했음을 나타냅니다.</li>
            <li><code>train_error</code>와 <code>test_error</code> 간의 차이가 크지 않으므로 과적합 문제가 없는 안정적인 학습을 보여줍니다.</li>
          </ul>
        </li>
        <li>
          <strong>결론:</strong>
          <ul>
            <li><strong>PINN</strong> 모델은 훈련 및 테스트 데이터에 대해 효과적으로 학습되었으며, 손실 감소 및 안정화를 통해 높은 일반화 성능을 보이고 있습니다.</li>
          </ul>
        </li>
      </ol>

      <div class="image-section.left">
        <img src="Deep learning10 images/37.png" alt="37" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>그래프 내용:</strong>
          <ul>
            <li><storng>검은색 선<code>Real_data</code></storng>: 실제 데이터의 위치 정보를 나타냅니다.</li>
            <li><storng>파란색 선<code>Predicted_train</code></storng>: 훈련 데이터를 사용하여 예측된 위치 정보를 나타냅니다.</li>
            <li><storng>빨간색 선<code>Predicted_test</code></storng>: 테스트 데이터를 사용하여 예측된 위치 정보를 나타냅니다.</li>
          </ul>
        </li>
        <li>
          <strong>결과 해석:</strong>
          <ul>
            <li>모델이 훈련 데이터(<code>Predicted_train</code>)와 테스트 데이터(<code>Predicted_test</code>) 모두에서 실제 데이터(<code>Real_data</code>)와 잘 일치하는 경향을 보입니다.</li>
            <li>테스트 데이터에서도 예측 값이 실제 값에 매우 근접하며 일반화 성능이 우수함을 확인할 수 있습니다.</li>
          </ul>
        </li>
        <li>
          <strong>결론:</strong>
          <ul>
            <li><strong>PINN</strong> 모델은 훈련 및 테스트 데이터 모두에서 높은 정확도를 달성하며, 물리적 정보와 데이터 간의 조화를 통해 뛰어난 예측 성능을 보였습니다.</li>
          </ul>
        </li>
      </ol>

      <p>상미분방정식의 정보가 모델 학습에 포함되면 데이터의 부족이나 노이즈를 물리적 제약이 보완하여 예측의 정확도가 높아지고, 훈련 및 테스트 손실이 안정적으로 감소하며 실제값과의 일치도가 높아집니다. 
        반면, 상미분방정식의 정보가 배제되면 모델은 데이터만으로 학습하게 되어 물리적 일관성을 확보하지 못하고, 예측 정확도가 낮아지며 손실 값이 크게 변동하거나 감소하지 않는 결과를 초래합니다.</p>
    </div>
  </div>
</body>
</html>
      
