<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GAN</title>
    <link rel="stylesheet" href="style-Deeplearning8.css">
</head>
<body>
  <div class="content-container">
    <!-- 제목 -->
      <h1 class="left"> DCGAN </h1>

    <div class="description-section">
      <h2>GAN 파생 기술</h2>
      <ul>
        <li>GAN은 생성자와 판별자가 서로 대결하면서 학습하는 구조이기 때문에 학습이 매우 불안정.</li>
        <li>생성자와 판별자 중 한쪽으로 치우친 훈련이 발생하면 성능에 문제가 생겨 정상적인 분류(진짜 혹은 가짜 분류)가 불가능.</li>
        <li>이러한 제약을 해결한 모델이 <strong>DCGAN</strong>(<em>Deep Convolutional GAN</em>).</li>
        <li>이름에서도 알 수 있듯이 DCGAN은 GAN 학습에 CNN을 사용하는 것.</li>
      </ul>

      <h2>DCGAN</h2>
      <ul>
        <li>
          DCGAN은 GAN과 동일하게 입력된 이미지를 바탕으로 그것과 매우 유사한 가짜 이미지를 만들고, 이를 평가하는 과정을 반복하여 실제와 매우 유사한 이미지를 생산하는 학습법.
        </li>
        <li>
          DCGAN 역시 생성자와 판별자 네트워크 두 개가 서로 적대적으로 학습하는 구조.
        </li>
      </ul>

      <ul>
        <li>그럼 왜 생성자 네트워크에서는 업샘플링을 사용하고, 판별자 네트워크에서는 스트라이드 합성곱을 사용할까?</li>
        <li><strong>생성자 네트워크</strong>에서는 노이즈를 입력으로 받아 훈련 데이터셋의 <strong>이미지와 같은 해상도를 가진 이미지를 생성해야 하기 때문에 공간을 확장시켜야</strong> 업샘플링이 필요.</li>
        <li>반면 <strong>판별자 네트워크</strong>는 실제 이미지와 생성자가 생성한 이미지 사이에서 어떤 이미지가 진짜인지 판단해야 하기 때문에 <strong>각 이미지의 특성을 추출할 수 있는 합성곱 연산</strong>을 수행.</li>
        <li>이때 스트라이드 합성곱을 사용하면 특성을 잘 추출할 수 있음.</li><br>
        <li>생성자가 수행하는 <strong>Deconvolution Layer</strong>는 이 때 손실된 정보를 복원하는 일을 한다.</li>
        <li><strong>Deconvolution</strong>은 여러 가지 의미로 사용되지만, 수학적으로는 정확히<strong>Convolution 연산의 역연산</strong>을 가리키는 개념이다.</li>
        <li>그렇다면 과연 프로그래밍적으로 완전한 역연산을 구현할 수 있을까?</li>
      </ul>

      <div class="image-section.left">
        <img src="Deep learning9 images/1.png" alt="1" class="deep-learning-image">
      </div>
      <ol>
        <li>
          <strong>입력 파라미터 설정:</strong>
          <ul>
            <li><code>input size = (1, 2, 3)</code> (입력 행렬 크기)</li>
            <li><code>Kernel size = 4</code> (커널 크기)</li>
            <li><code>stride = 1</code> (이동 간격)</li>
            <li><code>padding = 1</code> (경계 패딩)</li>
          </ul>
        </li>
        <li>
          <strong>출력 크기 계산:</strong>
          <ul>
            <li>
              출력 크기는 아래 공식을 사용합니다:<br>
                <img src="Deep learning9 images/2.png" alt="2">
            </li>
            <li>이 공식을 통해 출력 행(row) 크기가 5, 출력 열(column) 크기가 6임을 확인합니다.</li>
          </ul>
        </li>
        <li>
          <strong>ConvTranspose2d 연산 과정:</strong>
          <ul>
            <li><strong>Filter (kernel)</strong> 값이 주어진 상태에서 입력 행렬에 역연산이 수행됩니다.</li>
            <li>그림은 필터가 입력 값 <code>(1, 4)</code>에 적용되며 출력 값을 계산하는 과정을 시각적으로 보여줍니다.</li>
          </ul>
        </li>
      </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/3.png" alt="3" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>왼쪽 연산 과정:</strong>
                <ul>
                    <li>입력 행렬에서 값 <code>2</code>가 선택되어 <code>ConvTranspose2d</code> 연산이 수행됩니다.</li>
                    <li>필터(kernel)의 각 값이 입력 값 <code>2</code>와 곱해져 결과가 출력 행렬에 추가됩니다.</li>
                    <li>이 과정을 통해 출력 행렬의 특정 위치에 값이 채워지는 모습이 보입니다.</li>
                </ul>
            </li>
            <li>
                <strong>오른쪽 연산 과정:</strong>
                <ul>
                    <li>입력 행렬에서 값 <code>3</code>이 선택되어 동일한 연산이 반복됩니다.</li>
                    <li>필터(kernel)가 이동하며 값 <code>3</code>과 곱해진 결과가 출력 행렬의 다른 위치에 추가됩니다.</li>
                </ul>
            </li>
            <li>
                <strong>핵심 개념:</strong>
                <ul>
                    <li>
                        <strong>필터(kernel)</strong>은 입력 값과 곱셈 및 합산 연산을 통해 출력 행렬의 값을 생성합니다.
                    </li>
                    <li>필터가 입력 행렬 위에서 이동하며 연속적으로 연산이 수행됩니다.</li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/4.png" alt="4" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>입력 값 6에 대한 연산:</strong>
                <ul>
                    <li>입력 행렬의 값 <code>6</code>이 선택되어 <code>ConvTranspose2d</code> 연산이 수행됩니다.</li>
                    <li>필터(kernel)의 각 값이 입력 값 <code>6</code>과 곱해져 출력 행렬의 특정 위치에 더해집니다.</li>
                </ul>
            </li>
            <li>
                <strong>필터(kernel)와 출력:</strong>
                <ul>
                    <li>필터(kernel)의 값:</li>
                    <pre>
0.1  0.2  0.3  0.4
0.5  0.6  0.7  0.8
0.9  1.0  1.1  1.2
1.3  1.4  1.5  1.6</pre>
                    <li>필터 값이 입력 값 <code>6</code>에 곱해져 각 위치에서 출력값을 생성합니다.</li>
                </ul>
            </li>
            <li>
                <strong>출력 행렬 업데이트:</strong>
                <ul>
                    <li>출력 행렬의 각 위치는 연산 결과로 업데이트되며, 이는 입력 값 <code>6</code>과 필터의 곱셈 및 합산의 결과입니다.</li>
                    <li>연산 후, 출력 행렬에는 다음과 같은 값이 추가됩니다:</li>
                    <pre>
0.6  1.2  1.8  2.4
3.0  3.6  4.2  4.8
7.8  8.4  9.0  9.6</pre>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/5.png" alt="5" class="deep-learning-image">
        </div>
        <p>6개의 Input 값에 대한 결과를 element-wise addition 으로 최종 결과 도출</p>
        <ol>
            <li>
                <strong>6개의 입력 값에 대한 연산 결과:</strong>
                <ul>
                    <li>각 입력 값에 대해 <code>ConvTranspose2d</code> 연산이 수행되며, 이를 통해 6개의 개별 출력 행렬이 생성됩니다.</li>
                    <li>이 행렬들은 각각 필터와 입력 값의 곱셈 결과를 나타냅니다.</li>
                </ul>
            </li>
            <li>
                <strong>Element-wise Addition:</strong>
                <ul>
                    <li>6개의 출력 행렬을 같은 위치에 있는 요소끼리 더해 최종 결과를 생성합니다.</li>
                    <li>이 과정을 통해 모든 입력 값의 연산 결과가 하나의 출력 행렬로 결합됩니다.</li>
                </ul>
            </li>
            <li>
                <strong>최종 출력 (Final Result):</strong>
                <ul>
                    <li>합산된 결과는 최종 출력 행렬로 나타나며, 이는 입력 값들이 <code>ConvTranspose2d</code>를 통해 출력 데이터로 변환된 결과입니다.</li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/6.png" alt="6" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>Generator 구조:</strong>
                <ul>
                    <li>
                        Generator는 작은 랜덤 벡터(예: <code>fake_sz=100</code>)를 받아 이미지를 생성하는 역할을 합니다.
                    </li>
                    <li>
                        코드는 <code>nn.Sequential</code>을 사용하여 Generator의 계층을 정의합니다:
                        <ul>
                            <li>첫 번째 계층: <code>ConvTranspose2d</code>로 입력 벡터 크기를 4x4로 변환.</li>
                            <li>이후 계층: 점진적으로 해상도를 확대하며 채널 수를 줄이는 구조.</li>
                            <li>마지막 계층: 최종 이미지를 생성 (<code>tanh</code> 활성화 함수 사용).</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>ConvTranspose2d 연산:</strong>
                <ul>
                    <li>
                        <strong>입력 및 출력 크기 계산:</strong>
                        <ul>
                            <li>공식:<br>
                                    <img src="Deep learning9 images/7.png" alt="7">
                            </li>
                            <li>첫 번째 계층에서:<br>
                                <code>kernel=4, stride=1, padding=0</code> 설정.</li>
                            <li>입력 크기 <code>1x1</code> → 출력 크기 <code>4x4</code>.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>Generator 계층의 세부 구조:</strong>
                <ul>
                    <li>
                        각 계층에서 <code>ConvTranspose2d</code>, <code>BatchNorm2d</code>, <code>ReLU</code>가 조합되어 사용됨:
                        <ul>
                            <li><code>ConvTranspose2d</code>: 이미지를 점진적으로 확장.</li>
                            <li><code>BatchNorm2d</code>: 학습을 안정화하고 성능을 향상.</li>
                            <li><code>ReLU</code>: 활성화 함수로 비선형성을 추가.</li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/8.png" alt="8" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>ConvTranspose2d 설정</strong>
                <ul>
                    <li><strong>파라미터:</strong>
                        <ul>
                            <li><code>kernel_size = 4</code></li>
                            <li><code>stride = 2</code></li>
                            <li><code>padding = 1</code></li>
                        </ul>
                    </li>
                    <li>입력 크기: <code>4 × 4</code> (채널 수: 512).</li>
                    <li>출력 크기: <code>8 × 8</code> (채널 수: 256).</li>
                </ul>
            </li>
            <li>
                <strong>출력 크기 계산</strong>
                <ul>
                    <li><strong>공식:</strong></li>
                    <img src="Deep learning9 images/9.png" alt="9">
                    <li>입력 크기 <code>x_in = 4</code>,</li>
                    <li><code>kernel size = 4</code>,</li>
                    <li><code>padding = 1</code>,</li>
                    <li><code>stride = 2</code>.</li>
                    <li><strong>계산 결과:</strong></li>
                        <img src="Deep learning9 images/10.png" alt="10">
                </ul>
            </li>
            <li>
                <strong>Generator 계층의 역할</strong>
                <ul>
                    <li>두 번째 <code>ConvTranspose2d</code> 계층은:</li>
                    <ul>
                        <li>입력 <code>4 × 4</code> 데이터를 <code>8 × 8</code>로 확장.</li>
                        <li>채널 수를 <code>512 → 256</code>으로 감소.</li>
                    </ul>
                    <li>이 과정을 통해 Generator는 점진적으로 이미지를 확장하며 해상도를 높입니다.</li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/11.png" alt="11" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>Padding 적용 과정:</strong>
                <ul>
                    <li>
                        <code>padding = 1</code>이 설정되면, 입력 행렬 주변에 1칸씩 0으로 채운 <strong>패딩(padding)</strong>이 추가됩니다.
                    </li>
                    <li>계산 결과는 패딩을 포함한 크기에서 시작하여 출력 크기가 결정됩니다:</li>
                    <ul>
                        <li>패딩 적용 전: <code>8 × 8</code></li>
                        <li>패딩 적용 후: <code>10 × 10</code></li>
                    </ul>
                </ul>
            </li>
            <li>
                <strong>Stride 적용 과정:</strong>
                <ul>
                    <li>
                        <code>stride = 2</code>로 설정되면, 필터(kernel)가 한 번의 연산 후 <strong>2칸씩 이동</strong>합니다.
                    </li>
                    <li>필터가 이동하면서 새로운 위치에서 출력 값을 계산하고, 이를 출력 행렬에 기록합니다.</li>
                </ul>
            </li>
            <li>
                <strong>출력 과정 시작:</strong>
                <ul>
                    <li>첫 번째 계산: 필터가 <code>4 × 4</code> 입력의 첫 번째 위치에서 연산.</li>
                    <li>두 번째 계산: 필터가 2칸 이동한 후 새로운 위치에서 연산.</li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/12.png" alt="12" class="deep-learning-image">
        </div>
        <h3>결과 합산</h3>
        <ul>
            <li>필터가 입력 행렬 위에서 모든 가능한 위치를 계산한 후, 모든 출력 값을 결합하여 최종 결과 생성.</li>
            <li>최종 출력 행렬의 유효 크기: <code>8 × 8</code>.</li>
        </ul>

        <div class="image-section.left">
            <img src="Deep learning9 images/13.png" alt="13" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>입력과 필터 설정</strong>
                <ul>
                    <li>입력 행렬: <code>4 × 4</code>.</li>
                    <li>필터(kernel): <code>4 × 4</code> 크기의 값.</li>
                    <li><code>stride</code>: 2칸씩 이동하며 연산.</li>
                    <li><code>padding</code>: 입력 행렬의 경계에 0을 추가해 <code>10 × 10</code> 크기로 확장.</li>
                </ul>
            </li>
            <li>
                <strong>연산 과정</strong>
                <ul>
                    <li>필터가 <code>stride = 2</code> 설정에 따라 한 번에 2칸씩 이동하며 연산 수행.</li>
                    <li>필터 각 위치에서 계산된 결과는 출력 행렬의 점차 부분에 더해짐.</li>
                    <li>연산 결과로 <code>10 × 10</code> 크기의 초기 출력 행렬이 생성됨.</li>
                </ul>
            </li>
            <li>
                <strong>최종 출력</strong>
                <ul>
                    <li>겹치는 부분은 모든 값을 합산하여 최종 값을 결정.</li>
                    <li>패딩된 경계 부분은 제거되고, 실제 유효한 출력 크기는 <code>8 × 8</code> 도출.</li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/14.png" alt="14" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>GPU 설정 및 모델 초기화</strong>
                <ul>
                    <li>
                        <code>generator</code> (생성자)와 <code>discriminator</code> (판별자)를 초기화하고 GPU(<code>device</code>)에 할당.
                    </li>
                    <li><code>print(generator)</code> 및 <code>print(discriminator)</code> 명령을 사용해 모델 구조를 출력하여 확인.</li>
                </ul>
            </li>
            <li><strong>옵티마이저 정의</strong><ul>
                <li>생성자와 판별자의 옵티마이저를 각각 정의:
                    <ul>
                        <li><code>optim_g</code>: 생성자(Generator) 옵티마이저.</li>
                        <li><code>optim_d</code>: 판별자(Discriminator) 옵티마이저.</li>
                </li>
                <li>
                    <strong>Adam 옵티마이저 사용:</strong>
                    <ul>
                        <li>학습률(<code>lr</code>) = 0.0001.</li>
                        <li>모멘텀 계수(<code>beta1</code>, <code>beta2</code>) = (0.5, 0.999)로 설정 (기본값은 0.9, 0.999).</li>
                        <li><code>beta1 = 0.5</code> 설정은 GAN에서 안정적인 학습을 위해 일반적으로 사용.</li>
                    </ul>
                </li>
            </ul>
            </li>
            <li>
                <strong>손실 함수 정의</strong>
                <ul>
                    <li>
                        <code>nn.BCELoss()</code>: 이진 분류(Binary Classification)에서 사용되는 손실 함수.
                    </li>
                    <li>생성된 데이터와 실제 데이터를 구분하기 위한 손실 계산.</li>
                </ul>
            </li>
            <li>
                <strong>손실 추적</strong>
                <ul>
                    <li>
                        <code>losses_g</code>: 생성자의 손실 값을 저장하는 리스트.
                    </li>
                    <li>
                        <code>losses_d</code>: 판별자의 손실 값을 저장하는 리스트.
                    </li>
                    <li>에포크(<code>epoch</code>)마다 손실 변화를 추적하기 위해 사용.</li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/15.png" alt="15" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>SGD와 모멘텀의 차이</strong>
                <ul>
                    <li>
                        <strong>SGD (Stochastic Gradient Descent):</strong>
                        <ul>
                            <li>현재 위치에서 기울기(<strong>Gradient</strong>) 방향으로 이동하며 최적화.</li>
                            <li>하지만 기울기 변화가 큰 경우, 진동이 심해져 최적화 속도가 느려질 수 있음.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>SGD 모멘텀:</strong>
                        <ul>
                            <li>현재 속도(모멘텀)와 새로운 기울기를 조합하여 이동.</li>
                            <li>이전 속도를 활용해 관성을 추가함으로써 진동을 줄이고 빠르게 수렴.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>모멘텀 공식</strong>
                <ul>
                    <li>
                        <strong>속도 업데이트:</strong><br>
                        <img src="Deep learning9 images/16.png" alt="16">
                        <ul>
                            <li><strong>v<sub>t</sub></strong>: 현재 속도.</li>
                            <li><strong>ρ</strong>: 모멘텀 계수 (보통 0.9로 설정).</li>
                            <li><strong>∇f(x<sub>t</sub>)</strong>: 현재 기울기.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>위치 업데이트:</strong><br>
                        <img src="Deep learning9 images/17.png" alt="17"">
                        <ul>
                            <li><strong>α</strong>: 학습률.</li>
                            <li><strong>x<sub>t</sub></strong>: 현재 위치.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>그래프 해석</strong>
                <ul>
                    <li>현재 속도 (파란색 화살표): 이전 단계에서 이동한 방향과 크기.</li>
                    <li>기울기 (빨간색 화살표): 현재 위치에서의 최적화 방향.</li>
                    <li>두 벡터 합이 최종 이동 방향 (실제 스텝, 파란색 경로)을 결정.</li>
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/18.png" alt="18" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>SGD 모멘텀의 첫 번째 장점</strong>
                <ul>
                    <li>
                        <strong>얕은 지역 최소값에서 탈출:</strong>
                        <ul>
                            <li>관성의 효과로, SGD 모멘텀은 <strong>깊이가 얕은 지역 최소값(local minimum)</strong>에 빠지더라도 이를 벗어날 수 있습니다.</li>
                            <li>이는 진동 없이 더 부드럽고 효율적으로 최적화를 수행하게 합니다.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>울퉁불퉁한 지역에서 부드러운 이동:</strong>
                        <ul>
                            <li>기울기 변화가 심한 울퉁불퉁한 지역에서도 SGD 모멘텀은 속도 벡터를 활용하여 흔들림을 줄이고 안정적으로 이동합니다.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>SGD와 SGD 모멘텀 비교 (오른쪽 그래프):</strong>
                <ul>
                    <li>
                        <strong>SGD:</strong>
                        <ul>
                            <li>기울기를 따라 움직이지만, 잦은 진동으로 인해 학습 속도가 느리고 최적화가 불안정할 수 있음.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>SGD 모멘텀:</strong>
                        <ul>
                            <li>관성을 활용하여 더 빠르고 안정적으로 목표 지점에 도달.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>SGD 모멘텀의 두 가지 장점:</strong>
                <ul>
                    <li><strong>얕은 지역에서 탈출 및 부드러운 이동:</strong> 최적화 경로에서 효율적인 이동.</li>
                    <li><strong>빠른 학습 속도:</strong> 관성을 통해 안정적이고 효율적인 학습 경로 확보.</li>
                </ul>
            </li>
        </ol>
        
        <div class="image-section.left">
            <img src="Deep learning9 images/19.png" alt="19" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>RMSProp의 개념</strong>
                <ul>
                    <li><strong>목적:</strong> 경사 하강법에서 학습률을 곡면 변화량에 따라 적응적으로 조정.</li>
                    <li><strong>원리:</strong>
                        <ul>
                            <li>경사가 급격히 변하는 지점에서는 작은 스텝(학습률 감소).</li>
                            <li>경사가 완만한 지점에서는 큰 스텝(학습률 증가).</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>곡면 변화량에 따른 이동</strong>
                <ul>
                    <li><strong>최근 변화가 많을 때:</strong>
                        <ul>
                            <li>곡면 변화량이 크기 때문에 작은 스텝으로 이동하며 안정성을 유지.</li>
                        </ul>
                    </li>
                    <li><strong>최근 변화가 적을 때:</strong>
                        <ul>
                            <li>곡면이 완만할 때 큰 스텝으로 이동하여 빠른 최적화 진행.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>지수 가중 이동 평균 (Exponentially Weighted Moving Average)</strong>
                <ul>
                    <li>최근 경로의 변화를 측정할 때 전체 경로가 아닌 최근 변화만 반영.</li>
                    <li>이는 기울기 변화의 평균을 계산하여 변동성을 줄이고 학습을 안정화.</li>                
                </ul>
            </li>
        </ol>

        <div class="image-section.left">
            <img src="Deep learning9 images/20.png" alt="20" class="deep-learning-image">
        </div>
        <ol>
            <li>
                <strong>RMSProp의 핵심 수식</strong>
                <ul>
                    <li>
                        <strong>지수 가중 이동 평균:</strong>
                        <img src="Deep learning9 images/21.png" alt="21">
                        <ul>
                            <li><strong>r<sub>t</sub></strong>: 이전 스텝의 변화량 평균.</li>
                            <li><strong>β</strong>: 최근 변화량과 과거 변화량의 가중치를 조절하는 계수(보통 0.9 사용).</li>
                            <li><strong>∇f(x<sub>t</sub>)</strong>: 현재 스텝에서의 그래디언트 제곱 값.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>학습률 조정:</strong>
                        <img src="Deep learning9 images/22.png" alt="22">
                        <ul>
                            <li><strong>α</strong>: 학습률.</li>
                            <li><strong>ε</strong>: 0으로 나누는 문제를 방지하기 위한 작은 값.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>지수 가중 이동 평균의 유도</strong>
                <ul>
                    <li>
                        <img src="Deep learning9 images/23.png" alt="23">
                        <ul>
                            <li>최근 변화는 <code>1 - β</code> 계수에 의해 더 큰 영향을 받음.</li>
                            <li>과거 변화는 <code>βⁿ</code>에 의해 점차 작게 반영.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <strong>적응적 학습률 적용</strong>
                <ul>
                    <li><img src="Deep learning9 images/24.png" alt="24"> 를 통해 최근 곡면의 변화량을 반영하여 학습률을 동적으로 조정:</li>
                    <li>곡면 변화가 큰 경우,<img src="Deep learning9 images/25.png" alt="25">값이 커져 학습률이 줄어듦.
                    <li>곡면 변화가 작은 경우, 학습률이 커져 이동 속도가 빨라짐.</li>
                </ul>
            </li>
        </ol>
        
    </div>
  </div>
</body>
</html>
