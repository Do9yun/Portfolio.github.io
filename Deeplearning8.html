<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GAN</title>
    <link rel="stylesheet" href="style-Deeplearning8.css">
</head>
<body>
  <div class="content-container">
      <!-- 제목 -->
      <h1 class="left"> GAN </h1>  
      
      <div class="description-section">
          <h2> 생성모델이란? </h2>
          <ul>
              <li><strong>생성 모델(generative model)</strong>은 주어진 데이터를 학습하여 데이터 분포를 따르는 유사한 데이터를 생성하는 모델.</li>
          </ul>
          <h2> 개념 </h2>
          <div class="image-section.left">
              <img src="Deep learning8 images/1.png" alt="1" class="deep-learning-image">
          </div>
          <ul>
              <li>기존 합성곱 신경망에서 다른 이미지 분류, 이미지 검출 등은 입력 이미지(x)가 있을 때 그에 따른 정답(y)을 찾는 것</li>
              <li>예를 들어 개와 고양이 이미지 데이터셋이 주어졌을 때, 그 이미지를 개와 고양이로 분류하는 문제들을 다루었음</li>
              <li>이렇게 이미지를 분류하는 것을 ‘판별(자) 모델(discriminative model)’이라고 함</li>
              <li>일반적으로 판별자 모델에서는 이미지를 정확히 분류(구별)하고자 해당 이미지를 대표하는 특성들을 잘 찾는 것을 목표로 함</li>
              <li>예를 들어 개와 고양이를 구별하려면 개의 귀, 꼬리 등 특성을 찾는 것이 중요함</li>
              <li>판별자 모델에서 추출한 특성들의 조합을 이용하여 새로운 개와 고양이 이미지를 생성할 수 있는데, 이것을 ‘생성(자) 모델(generative model)’이라고 함</li>
              <li>즉, 생성 모델은 입력 이미지에 대한 데이터 분포 p(x)를 학습하여 새로운 이미지(새로운 이미지이면서 기존 이미지에서 특성을 추출했기 때문에 최대한 입력 이미지와 유사한 이미지)를 생성하는 것을 목표로 함</li>
          </ul>

          <h2>  생성 모델의 유형 </h2>
          <div class="image-section.left">
              <img src="Deep learning8 images/2.png" alt="2" class="deep-learning-image">
          </div>
          <ul>
              <li>생성 모델의 유형에는 다음 그림과 같이 모델의 확률 변수를 구하는 ‘변형 오토인코더 모델’과 확률 변수를 이용하지 않는 ‘GAN 모델’이 있음</li>
              <li>변형 오토인코더는 이미지의 잠재 공간(latent space)에서 샘플링하여 완전히 새로운 이미지나 기존 이미지를 변형하는 방식으로 학습을 진행</li>
              <li>GAN은 생성자와 판별자가 서로 경쟁하면서 가짜 이미지를 진짜 이미지와 최대한 비슷하게 만들도록 학습을 진행</li>
          </ul>

          <h2>적대적 생성 신경망(GAN)</h2>
          <div class="image-section.left">
              <img src="Deep learning8 images/main.png" alt="main" class="deep-learning-image">
          </div>
          <ul>
              <li>처음 적대적 생성 신경망(Generative Adversarial Network, GAN)을 제안한 이안 굿펠로우(Ian Goodfellow)는 GAN을 경찰과 위조지폐범 사이의 게임에 비유</li>
              <li>위조지폐범은 진짜와 같은 위조 화폐를 만들어 경찰을 속이고, 경찰은 진짜 화폐와 위조 화폐를 판별하여 위조지폐범을 검거</li>
              <li>위조지폐범과 경찰의 경쟁이 지속되면 어느 순간 위조지폐범은 진짜와 같은 위조지폐를 만들 수 있게 되고, 결국 경찰은 위조지폐와 실제 화폐를 구분할 수 없는 상태에 이르게 됨</li>
              <li>딥러닝 용어로 설명하자면, 경찰은 진짜 지폐와 위조지폐를 구분하는 판별자가 되며 위조지폐범은 위조지폐를 생성하는 생성자가 됨</li>
              <li>생성 모델은 최대한 진짜와 비슷한 데이터를 생성하려는 생성자와 진짜와 가짜를 구별하는 판별자가 각각 존재하여 서로 적대적으로 학습</li>
              <li>적대적 학습에서는 판별자를 먼저 학습시킨 후 생성자를 학습시키는 과정을 반복</li>
              <li>판별자 학습은 크게 두 단계로 진행</li>
          </ul>
          <div class="image-section.left">
              <img src="Deep learning8 images/3.png" alt="3" class="deep-learning-image">
          </div>
          <ul>
              <li>먼저 실제 이미지를 입력해서 네트워크(신경망)가 해당 이미지를 진짜로 분류하도록 학습</li>
              <li>그런 다음 생성자가 생성한 모조 이미지를 입력해서 해당 이미지를 가짜로 분류하도록 학습</li>
              <li>이 과정을 거쳐 판별자는 실제 이미지를 진짜로 분류하고, 모조 이미지를 가짜로 분류</li><br><br>
              <li>이와 같은 학습 과정을 반복하면 판별자와 생성자가 서로를 적대적인 경쟁자로 인식하여 모두 발전하게 됨</li>
              <li>결과적으로 생성자는 진짜 이미지에 완벽히 가까울 정도의 유사한 모조 이미지를 만들고, 이에 따라 판별자는 실제 이미지와 모조 이미지를 구분할 수 없게 됨</li>
              <li>즉, 생성자는 분류에 성공할 확률을 낮추고 판별자는 분류에 성공할 확률을 높이면서 서로 경쟁적으로 발전시키는 구조</li>
          </ul>

          <h2>GAN 동작 원리</h2>          
          <ul>
              <li>적대적 생성 신경망(GAN)은 생성자(Generator)와 판별자(Discriminator) 네트워크 두 개로 구성</li>
              <li>이름에서 알 수 있듯이 두 네트워크는 서로 적대적으로 경쟁하여 학습을 진행</li>
              <li>생성자 G는 판별자 D를 속이려고 원래 이미지와 최대한 비슷한 이미지를 만들도록 학습</li>
              <li>반대로 판별자 D는 원래 이미지와 생성자 G가 만든 이미지를 잘 구분하도록 학습을 진행</li>
          </ul>
          
          <div class="image-section.left">
              <img src="Deep learning8 images/4.png" alt="4" class="deep-learning-image">
          </div>
          <ul>
              <li>먼저 판별자 D부터 살펴보자</li>
              <li>판별자 D의 역할은 주어진 입력 이미지가 진짜 이미지인지 가짜 이미지인지 구별하는 것</li>
              <li>즉, 이미지 x가 입력으로 주어졌을 때 판별자 D의 출력에 해당하는 D(x)가 진짜 이미지일 확률을 반환</li>
          </ul>

          <div class="image-section.left">
              <img src="Deep learning8 images/5.png" alt="5" class="deep-learning-image">
          </div>
          <ul>
              <li>반면 생성자 G의 역할은 판별자 D가 진짜인지 가짜인지 구별할 수 없을 만큼 진짜와 같은 모조 이미지를 노이즈 데이터를 사용하여 만들어 내는 것</li>
              <li>예를 들어 실제 이미지인 알파벳 z가 입력으로 주어졌을 때 판별자는 z를 학습</li>
              <li>또한, 생성자는 임의의 노이즈 데이터를 사용하여 모조 이미지 z'(G(z))를 생성</li>
              <li>G(z)를 다시 판별자 D의 입력으로 주면 판별자는 G(z)가 실제 이미지일 확률을 반환</li>
              <li>실제 데이터를 판단하려고 판별자 D를 학습시킬 때는 생성자 G를 고정시킨 채 실제 이미지는 높은 확률을 반환하는 방향으로, 모조 이미지는 낮은 확률을 반환하는 방향으로 가중치를 업데이트</li><br><br>
              <li>GAN 구조를 살펴보았으니, 이제 GAN의 손실 함수를 살펴보자</li>
              <li>먼저 GAN의 손실 함수는 다음과 같음</li>
              <div class="image-section.left">
                  <img src="Deep learning8 images/6.png" alt="6" class="deep-learning-image">
              </div>
              <li>x &sim; P<sub>data</sub>(x): 실제 데이터에 대한 확률 분포에서 샘플링한 데이터</li>
              <li>z &sim; P<sub>z</sub>(z): 가우시안 분포를 사용하는 임의의 노이즈에서 샘플링한 데이터</li>
              <li>D(x): 판별자 D(x)가 1에 가까우면 진짜 데이터로, 0에 가까우면 가짜 데이터로 판단; 0이면 가짜를 의미</li>
              <li>D(G(z)): 생성자 G가 생성한 이미지인 G(z)가 1에 가까우면 진짜 데이터로, 0에 가까우면 가짜 데이터로 판단</li><br><br>

              <li>수식에서 판별자 D는 실제 이미지 x를 입력받을 경우 𝐷(𝑥)를 1로 예측하고, 생성자가 잠재 벡터에서 생성한 모조 이미지 𝐺(𝑧)를 입력받을 경우 𝐷(𝐺(𝑧))를 0으로 예측</li>
              <li>판별자가 모조 이미지 𝐺(𝑧)를 입력받을 경우 1로 예측하도록 하는 것이 목표</li>
              <li>전체 손실 함수는 복잡하므로 판별자 𝐷와 생성자 𝐺 부분으로 나누어서 살펴보자</li>
              <li>판별자 𝐷는 다음 식의 최댓값으로 파라미터를 업데이트하는 것을 목표로 함</li>
              <li>참고로 판별자는 앞의 수식에서 좌항과 우항을 모두 사용</li>
              <div class="image-section.left">
                  <img src="Deep learning8 images/7.png" alt="7" class="deep-learning-image">
              </div>
              <li>이때 판별자 입장에서는 𝐷(𝑥)=1D(x)=1, 𝐷(𝐺(𝑧))=0이 최상의 결과(진짜 이미지는 1, 가짜 이미지는 0을 출력할 경우)가 될 것이기 때문에 이 식의 최댓값으로 업데이트</li>
              <li>또한, 판별자 입장에서는 log(𝐷(𝑥))log(D(x))와 log⁡(1−𝐷(𝐺(𝑧))) 모두 최댓값이 되어야 함</li>
              <li>즉, 𝐷(𝑥)는 1이 되어야 실제 이미지를 진짜라고 분류하며, 1−𝐷(𝐺(𝑧))는 1이 되어야 생성자가 만든 모조 이미지를 가짜라고 분류</li>
              <li>반면에 생성자 𝐺는 다음 식의 최소값으로 파라미터를 업데이트하는 것을 목표로 함</li>
              <li>이때 생성자 입장에서는 𝐷(𝐺(𝑧))=1이 최상의 결과(판별자가 가짜 이미지를 1로 출력한 경우)가 될 것이기 때문에 이 식의 최소값으로 업데이트</li>
              <div class="image-section.left">
                  <img src="Deep learning8 images/8.png" alt="8" class="deep-learning-image">
              </div>
              <li>참고로 GAN을 학습시키려면 판별자와 생성자의 파라미터를 번갈아 가며 업데이트</li>
              <li>또한, 판별자의 파라미터를 업데이트할 때는 생성자의 파라미터를 고정시키고, 생성자의 파라미터를 업데이트할 때는 판별자의 파라미터를 고정</li>
          </ul>          

          <h2>GAN 구현</h2>
          <div class="image-section.left">
              <img src="Deep learning8 images/9.png" alt="9" class="deep-learning-image">
          </div>        
          <h4>데이터 전처리</h4>
          <li><code>transforms.Normalize((0.5,), (0.5,))</code>: GAN의 생성자와 판별자가 데이터의 값 범위를 동일하게 학습하도록 MNIST 데이터를 -1 ~ 1 범위로 정규화.</li>
          <h4>MNIST 데이터셋 로드</h4>
          <li><code>datasets.MNIST(root="./data", train=True, transform=transform, download=True)</code>: GAN 학습에 사용할 학습 데이터(MNIST)를 다운로드하고, 전처리를 적용.</li>
          <h4>DataLoader</h4>
          <li><code>DataLoader(train_dataset, batch_size=512, shuffle=True)</code>: GAN 학습에서 데이터가 배치 단위로 로드되며, 데이터 순서가 섞여 다양한 패턴을 학습 가능하도록 설정.</li><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/10.png" alt="10" class="deep-learning-image">
          </div>
          <ol>
              <li>
                  <code>nz = 128</code> (잠재 공간 크기):<br>
                  잠재 벡터 크기: 생성자의 입력으로 사용되는 랜덤 벡터 크기 설정.
              </li>
              <li>
                  <strong>Generator 클래스:</strong><br>
                  GAN에서 이미지를 생성하는 역할.
                  <ul>
                      <li>
                          <strong>구조:</strong>
                          <ul>
                              <li>
                                  <code>nn.Linear</code>: 잠재 벡터(<code>nz</code>)를 점진적으로 확대하여 출력 이미지를 생성.
                                  <ul>
                                      <li>128 → 256 → 512 → 1024 → 784</li>
                                  </ul>
                              </li>
                              <li>
                                  <code>nn.LeakyReLU(0.2)</code>: 비선형 활성화 함수로 Leaky ReLU 사용, 음수 영역에서도 작은 기울기를 보장하여 학습 안정화.
                              </li>
                              <li>
                                  <code>nn.Tanh()</code>: 최종 출력을 -1 ~ 1 범위로 스케일링하여 GAN의 데이터 정규화 범위와 일치.
                              </li>
                          </ul>
                      </li>
                      <li>
                          <code>forward(self, x):</code><br>
                          입력 잠재 벡터(<code>x</code>)를 신경망 계층(<code>self.main</code>)에 통과시켜 최종 이미지로 변환.
                          <ul>
                              <li>
                                  <code>.view(-1, 1, 28, 28)</code>: 생성된 데이터를 MNIST 이미지 크기(1채널, 28x28)로 재구성.
                              </li>
                          </ul>
                      </li>
                  </ul>
              </li>
          </ol>
          <p>GAN의 핵심 구성 요소인 생성자를 설계하여 랜덤 벡터로부터 학습 가능한 이미지를 생성하기 위해 사용되며, Leaky ReLU와 Tanh를 사용하여 안정적인 학습과 데이터 출력 범위를 정규화합니다.</p><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/11.png" alt="11" class="deep-learning-image">
          </div>
          <ul>
              <li>
                  <strong>Discriminator 클래스:</strong><br>
                  GAN에서 <strong>이미지의 진위 여부를 판단하는 역할</strong>.
                  <ul>
                      <li>
                          <strong>구조:</strong>
                          <ul>
                              <li>
                                  <code>nn.Linear</code>: 입력 이미지를 점진적으로 축소하여 진위 여부를 출력.
                                  <ul>
                                      <li>784 → 1024 → 512 → 256 → 1</li>
                                  </ul>
                              </li>
                              <li>
                                  <code>nn.LeakyReLU(0.2)</code>: 비선형 활성화 함수로 Leaky ReLU 사용, 음수 영역에서도 작은 기울기를 보장하여 학습 안정화.
                              </li>
                              <li>
                                  <code>nn.Dropout(0.3)</code>: 일부 뉴런을 무작위로 비활성화하여 과적합 방지.
                              </li>
                              <li>
                                  <code>nn.Sigmoid()</code>: 최종 출력을 0과 1 사이로 변환, 결과를 확률로 표현.
                              </li>
                          </ul>
                      </li>
                      <li>
                          <code>forward(self, x):</code><br>
                          입력 이미지 <code>(x)</code>를 평탄화(<code>.view(-1, 784)</code>)하여 신경망 계층(<code>self.main</code>)에 통과.<br>
                          결과값은 이미지가 진짜일 확률로 출력.
                      </li>
                  </ul>
              </li>
          </ul>        
          <p>판별자를 정의하여 입력 이미지가 진짜인지 가짜인지 학습하고 판단하기 위해 사용됩니다. 
              판별자의 출력은 생성자가 더 현실적인 이미지를 생성하도록 피드백을 제공합니다. 
              Leaky ReLU와 Dropout은 학습 안정화와 일반화 성능 향상에 기여합니다.</p><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/12.png" alt="12" class="deep-learning-image">
          </div>
          <ol>
              <li>
                  <strong>Generator와 Discriminator 초기화</strong>
                  <ul>
                      <li><code>generator = Generator(nz).to(device)</code>: 생성자(Generator)를 정의하고, 학습에 사용할 디바이스(GPU 또는 CPU)에 로드.</li>
                      <li><code>discriminator = Discriminator().to(device)</code>: 판별자(Discriminator)를 정의하고, 디바이스에 로드.</li>
                  </ul>
              </li>
              <li>
                  <strong>모델 구조 출력</strong>
                  <ul>
                      <li><code>print(generator)</code>와 <code>print(discriminator)</code>: 생성자와 판별자의 네트워크 구조를 출력해 확인.</li>
                  </ul>
              </li>
              <li>
                  <strong>최적화 도구 설정</strong>
                  <ul>
                      <li><code>optim_g = optim.Adam(generator.parameters(), lr=0.0002)</code>: 생성자(Generator) 학습을 위한 Adam 옵티마이저 설정, 학습률은 0.0002.</li>
                      <li><code>optim_d = optim.Adam(discriminator.parameters(), lr=0.0002)</code>: 판별자(Discriminator) 학습을 위한 Adam 옵티마이저 설정, 학습률은 0.0002.</li>
                  </ul>
              </li>
              <li>
                  <strong>손실 함수 정의</strong>
                  <ul>
                      <li><code>criterion = nn.BCELoss()</code>: Binary Cross Entropy Loss를 손실 함수로 사용. 진짜/가짜 여부를 판별할 확률에 기반한 손실 계산.</li>
                  </ul>
              </li>
              <li>
                  <strong>손실 기록 리스트 초기화</strong>
                  <ul>
                      <li><code>losses_g = []</code>: 생성자(Generator) 손실 기록을 저장할 리스트.</li>
                      <li><code>losses_d = []</code>: 판별자(Discriminator) 손실 기록을 저장할 리스트.</li>
                  </ul>
              </li>
          </ol>
          <p>Generator와 Discriminator를 초기화하고, 학습에 필요한 손실 함수와 최적화 도구를 설정하기 위해 사용됩니다. 
              이는 GAN 학습의 시작점으로, 네트워크 구조와 학습 설정을 명확히 하고, 학습 중 손실 변화를 기록하여 성능을 평가하기 위함입니다.</p><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/13.png" alt="13" class="deep-learning-image">
          </div>
          <ol>
              <li>
                  <strong>에포크 설정</strong>
                  <ul>
                      <li><code>epochs = 500</code>: 모델 학습 반복 횟수를 500으로 설정.</li>
                  </ul>
              </li>
              <li>
                  <strong>학습 루프 시작</strong>
                  <ul>
                      <li><code>for epoch in range(epochs):</code>: 지정된 에포크 수만큼 학습 루프 실행.</li>
                  </ul>
              </li>
              <li>
                  <strong>손실 초기화</strong>
                  <ul>
                      <li><code>loss_g = 0.0, loss_d = 0.0</code>: 각 에포크마다 생성자(Generator)와 판별자(Discriminator)의 손실값을 초기화.</li>
                  </ul>
              </li>
              <li>
                  <strong>데이터 로드 및 준비</strong>
                  <ul>
                      <li>
                          <code>for idx, data in enumerate(train_loader):</code><br>
                          학습 데이터셋을 배치 단위로 로드.
                      </li>
                      <li>
                          <code>image, _ = data</code>: 입력 이미지 데이터를 가져옴(MNIST 데이터셋에서 레이블은 무시).
                      </li>
                      <li>
                          <code>data_real = image.to(device)</code>: 로드한 이미지를 학습 디바이스(GPU 또는 CPU)로 이동.
                      </li>
                      <li>
                          <code>b_size = len(data_real)</code>: 현재 배치 크기 계산.
                      </li>
                  </ul>
              </li>
          </ol>
          <p>GAN 학습의 기본 루프를 설정하고, 각 에포크와 배치에서 사용할 데이터를 준비하기 위해 사용됩니다. 
              이 코드에서는 손실 초기화를 통해 각 에포크에서 독립적으로 손실을 계산할 수 있도록 하고, 배치 단위로 데이터를 로드하여 학습 효율성을 높입니다. 
              디바이스로 데이터를 이동시켜 모델과 데이터 간 연산을 원활하게 수행할 수 있도록 설정합니다.</p><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/14.png" alt="14" class="deep-learning-image">
          </div>
          <ol>
              <li>
                  <strong>배치 크기 설정 및 라벨 정의</strong>
                  <ul>
                      <li><code>b_size = data_real.size(0)</code>: 입력된 진짜 데이터(<code>data_real</code>)의 배치 크기 계산.</li>
                      <li><code>real_label = torch.ones(b_size, 1).to(device)</code>: 진짜 데이터에 대한 정답 라벨(1)을 생성하여 디바이스로 이동.</li>
                      <li><code>fake_label = torch.zeros(b_size, 1).to(device)</code>: 가짜 데이터에 대한 정답 라벨(0)을 생성하여 디바이스로 이동.</li>
                  </ul>
              </li>
              <li>
                  <strong>그래디언트 초기화</strong>
                  <ul>
                      <li><code>optimizer.zero_grad()</code>: 이전에 계산된 그래디언트를 초기화하여 새로운 그래디언트를 계산 준비.</li>
                  </ul>
              </li>
              <li>
                  <strong>진짜 데이터에 대한 손실 계산</strong>
                  <ul>
                      <li><code>output_real = discriminator(data_real)</code>: 판별자가 진짜 데이터를 입력하여 예측값 생성.</li>
                      <li><code>loss_real = criterion(output_real, real_label)</code>: 진짜 데이터를 진짜로 분류하는 손실 계산(Binary Cross Entropy Loss).</li>
                  </ul>
              </li>
              <li>
                  <strong>가짜 데이터에 대한 손실 계산</strong>
                  <ul>
                      <li><code>output_fake = discriminator(data_fake)</code>: 판별자가 가짜 데이터를 입력하여 예측값 생성.</li>
                      <li><code>loss_fake = criterion(output_fake, fake_label)</code>: 가짜 데이터를 가짜로 분류하는 손실 계산(Binary Cross Entropy Loss).</li>
                  </ul>
              </li>
              <li>
                  <strong>총 손실 계산 및 역전파</strong>
                  <ul>
                      <li><code>loss_total = (loss_real + loss_fake) / 2</code>: 진짜와 가짜 데이터에 대한 손실의 평균을 계산.</li>
                      <li><code>loss_total.backward()</code>: 판별자에 대해 손실에 대한 그래디언트 계산.</li>
                      <li><code>optimizer.step()</code>: 판별자의 파라미터를 업데이트하여 성능 향상.</li>
                  </ul>
              </li>
              <li>
                  <strong>손실 반환</strong>
                  <ul>
                      <li><code>return loss_total</code>: 판별자의 총 손실을 반환.</li>
                  </ul>
              </li>
          </ol>
          <p> 판별자를 학습시키기 위한 함수로, 진짜 데이터와 가짜 데이터에 대한 손실을 각각 계산하여 판별자가 진짜와 가짜를 더 정확히 구분하도록 학습시킵니다.
              손실값을 통해 판별자의 성능을 평가하고, 생성자 학습에 사용할 신호를 제공합니다. 
              이를 통해 GAN의 판별자가 생성자의 출력을 더 잘 판단할 수 있도록 학습됩니다.</p><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/15.png" alt="15" class="deep-learning-image">
          </div>
          <ol>
              <li>
                  <strong>배치 크기와 라벨 정의</strong>
                  <ul>
                      <li><code>b_size = data_fake.size(0)</code>: 생성된 가짜 데이터의 배치 크기를 계산.</li>
                      <li>
                          <code>real_label = torch.ones(b_size, 1).to(device)</code>:<br>
                          생성자가 판별자를 속이도록 가짜 데이터를 진짜로 분류하게 만들기 위해 <strong>진짜 데이터 라벨(1)</strong>을 생성.
                      </li>
                  </ul>
              </li>
              <li>
                  <strong>그래디언트 초기화</strong>
                  <ul>
                      <li><code>optimizer.zero_grad()</code>: 이전에 계산된 그래디언트를 초기화하여 새로운 그래디언트 계산 준비.</li>
                  </ul>
              </li>
              <li>
                  <strong>손실 계산</strong>
                  <ul>
                      <li><code>output = discriminator(data_fake)</code>: 가짜 데이터를 판별자에 입력하여 진짜로 분류할 확률 출력.</li>
                      <li>
                          <code>loss = criterion(output, real_label)</code>:<br>
                          가짜 데이터를 진짜로 분류하도록 하는 손실 계산(Binary Cross Entropy Loss).
                      </li>
                  </ul>
              </li>
              <li>
                  <strong>역전파 및 최적화</strong>
                  <ul>
                      <li><code>loss.backward()</code>: 생성자의 그래디언트를 계산하여 손실을 줄이는 방향으로 학습.</li>                      
                      <li><code>optimizer.step()</code>: 생성자의 파라미터를 업데이트하여 학습 진행.</li>
                  </ul>
              </li>
              <li>
                  <strong>손실 반환</strong>
                  <ul>
                      <li><code>return loss</code>: 생성자의 손실값을 반환하여 학습 진행 상황을 모니터링.</li>
                  </ul>
              </li>
          </ol>        
          <p>생성자를 학습시키기 위한 함수로, 판별자를 속여 가짜 데이터를 진짜로 분류하도록 유도합니다. 
              생성자가 생성한 데이터를 판별자가 진짜로 인식할 확률을 높이는 방향으로 손실을 줄여 나가며, GAN의 학습을 진행합니다. 
              이를 통해 생성자가 점점 더 현실적인 데이터를 생성하도록 개선됩니다.</p><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/16.png" alt="16" class="deep-learning-image">
          </div>
          <ol>
              <li>
                  <strong>학습 설정</strong>
                  <ul>
                      <li><code>epochs = 500</code>: 학습 반복 횟수를 500으로 설정.</li>
                      <li><code>loss_g = 0.0, loss_d = 0.0</code>: 에포크별로 생성자(Generator)와 판별자(Discriminator)의 손실을 초기화.</li>
                  </ul>
              </li>
              <li>
                  <strong>데이터 로드</strong>
                  <ul>
                      <li><code>for idx, data in enumerate(train_loader):</code>: 배치 단위로 학습 데이터를 로드.</li>
                      <li><code>data_real = image.to(device)</code>: 진짜 데이터 이미지를 학습 디바이스(GPU/CPU)로 이동.</li>
                      <li><code>b_size = len(data_real)</code>: 현재 배치의 크기를 계산.</li>
                  </ul>
              </li>
              <li>
                  <strong>판별자 학습</strong>
                  <ul>
                      <li><code>data_fake = generator(torch.randn(b_size, nz).to(device))</code>: 생성자가 잠재 벡터(<code>torch.randn</code>)를 입력받아 가짜 데이터를 생성.</li>
                      <li><code>loss_d = train_discriminator(optim_d, data_real, data_fake)</code>: 판별자를 학습시키고, 손실을 누적.</li>
                  </ul>
              </li>
              <li>
                  <strong>생성자 학습</strong>
                  <ul>
                      <li><code>data_fake = generator(torch.randn(b_size, nz).to(device))</code>: 생성자가 새로운 가짜 데이터를 생성.</li>
                      <li><code>loss_g = train_generator(optim_g, data_fake)</code>: 생성자를 학습시키고, 손실을 누적.</li>
                  </ul>
              </li>
              <li>
                  <strong>에포크 손실 계산</strong>
                  <ul>
                      <li><code>epoch_loss_g = loss_g / idx, epoch_loss_d = loss_d / idx</code>: 에포크별 평균 생성자와 판별자 손실 계산.</li>
                      <li><code>losses_g.append(epoch_loss_g), losses_d.append(epoch_loss_d)</code>: 손실 기록을 저장.</li>
                  </ul>
              </li>
              <li>
                  <strong>학습 진행 상태 출력</strong>
                  <ul>
                      <li><code>if epoch % 20 == 0:</code>: 20 에포크마다 학습 상태를 출력.</li>
                      <li>생성자와 판별자의 손실을 출력해 학습 과정을 모니터링.</li>
                  </ul>
              </li>
          </ol>
          <p>GAN의 학습 루프를 구현하여 생성자와 판별자를 반복적으로 학습시키고, 손실을 계산 및 기록합니다. 
              생성자와 판별자의 손실 변화를 통해 학습이 잘 진행되는지 모니터링할 수 있으며, 학습 도중 생성자와 판별자의 균형 상태를 확인하기 위해 사용됩니다.</p>

          <div class="image-section.left">
              <img src="Deep learning8 images/17.png" alt="17" class="deep-learning-image">
          </div>
          <h3>손실 그래프 시작화</h3>
          <ul>
              <li><code>plt.figure()</code>: 새로운 그래프를 그리기 위한 Figure 생성.</li>
              <li>
                  <code>plt.plot(torch.Tensor(losses_g), label='Generator Loss')</code>:<br>
                  에포크별 생성자 손실(<code>losses_g</code>)을 텐서로 변환하여 그래프로 출력.<br>
                  <code>label='Generator Loss'</code>: 생성자 손실의 범례 추가.
              </li>
              <li>
                  <code>plt.plot(torch.Tensor(losses_d), label='Discriminator Loss')</code>:<br>
                  에포크별 판별자 손실(<code>losses_d</code>)을 텐서로 변환하여 그래프로 출력.<br>
                  <code>label='Discriminator Loss'</code>: 판별자 손실의 범례 추가.
              </li>
              <li><code>plt.legend()</code>: 범례를 그래프에 표시.</li>
          </ul>
          <h3>결과 확인</h3>
          <ul>
              <li>
                  <strong>Generator Loss (생성자 손실):</strong>
                  <ul>
                      <li>초기에는 높은 손실값을 보이다가 점차 감소하며 안정화.</li>
                      <li>이는 생성자가 점점 더 현실적인 데이터를 생성하도록 학습되었음을 나타냄.</li>
                  </ul>
              </li>
              <li>
                  <strong>Discriminator Loss (판별자 손실):</strong>
                  <ul>
                      <li>초기에는 손실이 낮지만 점차 증가하며 일정 수준에서 유지.</li>
                      <li>이는 판별자가 생성자가 생성한 데이터를 점점 더 구분하기 어려워짐을 의미.</li>
                  </ul>
              </li>
          </ul>
          <p>GAN 학습 과정에서 생성자와 판별자의 손실 변화를 시각적으로 분석하기 위해 사용됩니다. 
              손실 그래프를 통해 학습이 잘 진행되고 있는지, 두 네트워크 간 균형이 유지되고 있는지 확인할 수 있습니다. 
              이를 통해 GAN의 학습이 수렴하고 있는지를 직관적으로 이해할 수 있습니다.</p><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/18.png" alt="18" class="deep-learning-image">
          </div>
          <li>GAN 학습이 진행될수록 생성자가 점점 더 현실적인 숫자 이미지를 생성하는 과정을 보여줍니다.</li>
          <li>초기 노이즈 상태에서 <strong>MNIST 데이터 분포</strong>를 학습해 가는 생성자의 성능 향상을 시각적으로 확인할 수 있습니다.</li>
          <li>학습이 충분히 이루어지면 생성자가 실제 데이터와 구분하기 어려운 고품질 데이터를 생성할 수 있음을 나타냅니다.</li><br>

          <div class="image-section.left">
              <img src="Deep learning8 images/19.png" alt="19" class="deep-learning-image">
          </div>
          <h3>왼쪽 이미지 (생성된 이미지)</h3>
          <ol>
              <li>
                  <strong>코드 설명</strong>
                  <ul>
                      <li>
                          <code>fake_images_img = np.reshape(fake_images.data.cpu().numpy()[i], (28, 28))</code>:<br>
                          GAN 생성자(Generator)가 생성한 가짜 이미지를 CPU로 이동하고, NumPy 배열로 변환한 후, 28x28 크기로 재구성.
                      </li>
                      <li>
                          <code>plt.imshow(fake_images_img, cmap='gray')</code>: 생성된 이미지를 흑백(그레이스케일)으로 출력.
                      </li>
                  </ul>
              </li>
              <li>
                  <strong>결과</strong>
                  <ul>
                      <li>GAN의 생성자가 생성한 숫자 이미지.</li>
                      <li>이미지 품질은 GAN 학습의 진행 정도에 따라 달라지며, 이 경우 일부 노이즈가 남아 있는 모습.</li>
                  </ul>
              </li>
          </ol>          
          <h3>오른쪽 이미지 (진짜 데이터)</h3>
          <ol>
              <li>
                  <strong>코드 설명</strong>
                  <ul>
                      <li>
                          <code>image, label = train_dataset[i]</code>:<br>
                          실제 학습 데이터셋에서 숫자 이미지와 해당 레이블을 로드.
                      </li>
                      <li>
                          <code>plt.imshow(np.transpose(image, (1, 2, 0)), cmap='gray')</code>:<br>
                          학습 데이터 이미지를 채널 순서를 변경(<code>(1, 2, 0)</code>)하여 그레이스케일로 출력.
                      </li>
                  </ul>
              </li>
              <li>
                  <strong>결과</strong>
                  <ul>
                      <li>실제 MNIST 데이터셋에서 가져온 숫자 이미지.</li>
                      <li>희미하고 깔끔한 숫자 형태를 보여줌.</li><br>
                  </ul>
              </li>
          </ol>
          <p>GAN 생성자가 학습한 결과로 생성된 이미지는 숫자 형태를 어느 정도 모방했지만, 일부 노이즈와 왜곡이 남아 있는 상태입니다. 
              반면, 실제 MNIST 데이터셋에서 제공된 진짜 이미지는 명확한 숫자 형태를 보여주며, 생성된 이미지와 비교 기준이 됩니다.
              이 비교는 생성자가 얼마나 현실적인 데이터를 생성하고 있는지 평가하는 데 활용되며, GAN 학습이 잘 진행될수록 생성된 이미지는 실제 이미지와 점점 더 유사해집니다.</p><br><br>

          <p>오늘은 적대적 생성 신경망(GAN)의 개념, 구조, 학습 과정, 그리고 코드 구현 방법에 대해 알아보았습니다. 
        GAN은 생성자와 판별자가 적대적으로 학습하며 현실적인 데이터를 생성하는 데 매우 효과적인 기술입니다. 
        생성자와 판별자의 경쟁 구조를 통해 학습이 진행되며, 이 과정에서 생성자는 점점 더 진짜와 유사한 데이터를 생성할 수 있게 됩니다.</p>
        <p>다음에는 딥러닝 모델에서 자주 활용되는 **DCGAN(Deep Convolutional GAN)**에 대해 알아보며, 
        합성곱 신경망을 기반으로 한 생성 모델의 성능과 활용 가능성을 탐구하겠습니다.</p>
        <p>감사합니다!</p>
      </div>
  </div>   
</body>
</html>
